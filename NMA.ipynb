{
 "metadata": {
  "name": "",
  "signature": "sha256:6c6092f1acbde715d665f0e9e92f6d8d3148c4c4b83b24b571f5e9297f3077c1"
 },
 "nbformat": 3,
 "nbformat_minor": 0,
 "worksheets": [
  {
   "cells": [
    {
     "cell_type": "heading",
     "level": 1,
     "metadata": {},
     "source": [
      "Neuron Modeling Analysis"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "import numpy as np\n",
      "import scipy\n",
      "from scipy import spatial, signal, fft, arange\n",
      "import pandas as pd\n",
      "import matplotlib.pyplot as plt\n",
      "from pandas import Series, DataFrame\n",
      "import time as t\n",
      "from PIL import Image\n",
      "import sys\n",
      "import os, errno\n",
      "import matplotlib.patches as patches\n",
      "from pandas.tools.plotting import autocorrelation_plot\n",
      "#from pyeeg import * \n",
      "from numpy import NaN, Inf, arange, isscalar, asarray, array\n",
      "from matplotlib.backends.backend_pdf import PdfPages\n",
      "import utility\n",
      "\n",
      "def mkdir_p(path):\n",
      "    '''\n",
      "    This function creates a folder at the end of the specified path, unless the folder already exsists. \n",
      "    '''\n",
      "    try:\n",
      "        os.makedirs(path)\n",
      "    except OSError as exc: # Python >2.5\n",
      "        if exc.errno == errno.EEXIST and os.path.isdir(path):\n",
      "            pass #do nothing if the error occurs because the path already exists\n",
      "        else: raise #re-raises the error\n",
      "    \n",
      "def delta_tuner(dataframe, epsilon, rate): #choose which data to use to tune. can be either selected list or full ist. AD reccoments full list.\n",
      "    '''\n",
      "    this function takes a dataframe of time series data and runs peak detection iteritvely. \n",
      "    since peak detection always has the the range of delta values of 0 to the max of stack,\n",
      "    epsiolon is used to be the number of divisions of that range to test. 1 being the minimum for epsilon, which is the exact middle of the range.\n",
      "    the function will return a results table (average # of events) and (# ROIs with events>1) on their own axis.\n",
      "    the graph will be click able, as to obtain the delta value that generated that point.\n",
      "    data results are not saved.\n",
      "    '''\n",
      "    \n",
      "    range_array = np.linspace(0, max(dataframe.max())/2, num = epsilon) #create the array of which delta values to test. the range is from zero (although zero is not used) to half of the max value from the entire data frame. epsilon is used to determine the number of slices to make\n",
      "    \n",
      "    results_average = Series(index = range_array) #the empty series to store results\n",
      "    results_num = Series (index = range_array) #an empty series to store results\n",
      "    #results_perc = Series (index = range_array)\n",
      "    \n",
      "    for delta in range_array[1:]: #for each delta value in the array\n",
      "        \n",
      "        peak_amp_temp, peak_sets_temp_x, peak_sets_temp_y = event_detection(dataframe,delta, rate) #perform event detection with the delta\n",
      "\n",
      "        event_counts = peak_amp_temp.loc['count'] #count the number of events, which is a row in the peak_amp_temp array\n",
      "        average_num_events = event_counts.mean() #average the counts, to obtain (average # events/roi)\n",
      "        num_roi = event_counts[event_counts>=1].count() #count the number of ROIs with more than one event\n",
      "        \n",
      "        #perc_roi = num_roi/len(data_smooth.columns)\n",
      "\n",
      "        results_average[delta] = average_num_events \n",
      "        results_num[delta] = num_roi\n",
      "        #results_perc[delta]= perc_roi\n",
      "    return results_average, results_num\n",
      "\n",
      "def savitzky_golay(y, window_size, order, deriv=0, rate=1):\n",
      "    r\"\"\"Smooth (and optionally differentiate) data with a Savitzky-Golay filter.\n",
      "    The Savitzky-Golay filter removes high frequency noise from data.\n",
      "    It has the advantage of preserving the original shape and\n",
      "    features of the signal better than other types of filtering\n",
      "    approaches, such as moving averages techniques.\n",
      "    Parameters\n",
      "    ----------\n",
      "    y : array_like, shape (N,)\n",
      "        the values of the time history of the signal.\n",
      "    window_size : int\n",
      "        the length of the window. Must be an odd integer number.\n",
      "    order : int\n",
      "        the order of the polynomial used in the filtering.\n",
      "        Must be less then `window_size` - 1.\n",
      "    deriv: int\n",
      "        the order of the derivative to compute (default = 0 means only smoothing)\n",
      "    Returns\n",
      "    -------\n",
      "    ys : ndarray, shape (N)\n",
      "        the smoothed signal (or it's n-th derivative).\n",
      "    Notes\n",
      "    -----\n",
      "    The Savitzky-Golay is a type of low-pass filter, particularly\n",
      "    suited for smoothing noisy data. The main idea behind this\n",
      "    approach is to make for each point a least-square fit with a\n",
      "    polynomial of high order over a odd-sized window centered at\n",
      "    the point.\n",
      "    Examples\n",
      "    --------\n",
      "    t = np.linspace(-4, 4, 500)\n",
      "    y = np.exp( -t**2 ) + np.random.normal(0, 0.05, t.shape)\n",
      "    ysg = savitzky_golay(y, window_size=31, order=4)\n",
      "    import matplotlib.pyplot as plt\n",
      "    plt.plot(t, y, label='Noisy signal')\n",
      "    plt.plot(t, np.exp(-t**2), 'k', lw=1.5, label='Original signal')\n",
      "    plt.plot(t, ysg, 'r', label='Filtered signal')\n",
      "    plt.legend()\n",
      "    plt.show()\n",
      "    References\n",
      "    ----------\n",
      "    .. [1] A. Savitzky, M. J. E. Golay, Smoothing and Differentiation of\n",
      "       Data by Simplified Least Squares Procedures. Analytical\n",
      "       Chemistry, 1964, 36 (8), pp 1627-1639.\n",
      "    .. [2] Numerical Recipes 3rd Edition: The Art of Scientific Computing\n",
      "       W.H. Press, S.A. Teukolsky, W.T. Vetterling, B.P. Flannery\n",
      "       Cambridge University Press ISBN-13: 9780521880688\n",
      "    \"\"\"\n",
      "    import numpy as np\n",
      "    from math import factorial\n",
      "\n",
      "    try:\n",
      "        window_size = np.abs(np.int(window_size))\n",
      "        order = np.abs(np.int(order))\n",
      "    except ValueError, msg:\n",
      "        raise ValueError(\"window_size and order have to be of type int\")\n",
      "    if window_size % 2 != 1 or window_size < 1:\n",
      "        raise TypeError(\"window_size size must be a positive odd number\")\n",
      "    if window_size < order + 2:\n",
      "        raise TypeError(\"window_size is too small for the polynomials order\")\n",
      "    order_range = range(order+1)\n",
      "    half_window = (window_size -1) // 2\n",
      "    # precompute coefficients\n",
      "    b = np.mat([[k**i for i in order_range] for k in range(-half_window, half_window+1)])\n",
      "    m = np.linalg.pinv(b).A[deriv] * rate**deriv * factorial(deriv)\n",
      "    # pad the signal at the extremes with\n",
      "    # values taken from the signal itself\n",
      "    firstvals = y[0] - np.abs( y[1:half_window+1][::-1] - y[0] )\n",
      "    lastvals = y[-1] + np.abs(y[-half_window-1:-1][::-1] - y[-1])\n",
      "    y = np.concatenate((firstvals, y, lastvals))\n",
      "    return np.convolve( m[::-1], y, mode='valid')\n",
      "\n",
      "def peakdet(v, delta, x = None):\n",
      "    \"\"\"\n",
      "    Converted from MATLAB script at http://billauer.co.il/peakdet.html\n",
      "    \n",
      "    Returns two arrays\n",
      "    \n",
      "    function [maxtab, mintab]=peakdet(v, delta, x)\n",
      "    %PEAKDET Detect peaks in a vector\n",
      "    %        [MAXTAB, MINTAB] = PEAKDET(V, DELTA) finds the local\n",
      "    %        maxima and minima (\"peaks\") in the vector V.\n",
      "    %        MAXTAB and MINTAB consists of two columns. Column 1\n",
      "    %        contains indices in V, and column 2 the found values.\n",
      "    %      \n",
      "    %        With [MAXTAB, MINTAB] = PEAKDET(V, DELTA, X) the indices\n",
      "    %        in MAXTAB and MINTAB are replaced with the corresponding\n",
      "    %        X-values.\n",
      "    %\n",
      "    %        A point is considered a maximum peak if it has the maximal\n",
      "    %        value, and was preceded (to the left) by a value lower by\n",
      "    %        DELTA.\n",
      "    \n",
      "    % Eli Billauer, 3.4.05 (Explicitly not copyrighted).\n",
      "    % This function is released to the public domain; Any use is allowed.\n",
      "    \n",
      "    \"\"\"\n",
      "    maxtab = []\n",
      "    #mintab = []\n",
      "       \n",
      "    if x is None:\n",
      "        x = arange(len(v))\n",
      "    \n",
      "    v = asarray(v)\n",
      "    \n",
      "    if len(v) != len(x):\n",
      "        sys.exit('Input vectors v and x must have same length')\n",
      "    \n",
      "    if not isscalar(delta):\n",
      "        sys.exit('Input argument delta must be a scalar')\n",
      "    \n",
      "    if delta <= 0:\n",
      "        sys.exit('Input argument delta must be positive')\n",
      "    \n",
      "    mn, mx = Inf, -Inf\n",
      "    mnpos, mxpos = NaN, NaN\n",
      "    \n",
      "    lookformax = True\n",
      "    \n",
      "    for i in arange(len(v)):\n",
      "        this = v[i]\n",
      "        if this > mx:\n",
      "            mx = this\n",
      "            mxpos = x[i]\n",
      "        if this < mn:\n",
      "            mn = this\n",
      "            mnpos = x[i]\n",
      "        \n",
      "        if lookformax:\n",
      "            if this < mx-delta:\n",
      "                maxtab.append((mxpos, mx))\n",
      "                mn = this\n",
      "                mnpos = x[i]\n",
      "                lookformax = False\n",
      "        else:\n",
      "            if this > mn+delta:\n",
      "                #mintab.append((mnpos, mn))\n",
      "                mx = this\n",
      "                mxpos = x[i]\n",
      "                lookformax = True\n",
      " \n",
      "    return array(maxtab)#, array(mintab)\n",
      "\n",
      "\n",
      "def event_detection(data, delta, rate):\n",
      "    '''\n",
      "    do peak detect on a dataframe. takes a delta value and the rate.\n",
      "    A point is considered a maximum peak if it has the maximal value, and was preceded (to the left) by a value lower by DELTA.\n",
      "    '''\n",
      "    \n",
      "    #results storage\n",
      "    peak_amp_temp = DataFrame()\n",
      "    rr_int_temp = DataFrame()\n",
      "    peak_sets_temp_x = {} #time\n",
      "    peak_sets_temp_y = {} #amplitude\n",
      "\n",
      "    for label, column in data.iteritems(): #for each column in the data frame\n",
      "        start_time = t.clock()\n",
      "        time = column.index.tolist() #time array\n",
      "        col = column.tolist() #amplitude array\n",
      "\n",
      "        #peakdet\n",
      "        maxtab = peakdet(col, delta,None)\n",
      "\n",
      "        maxtab = np.array(maxtab)\n",
      "\n",
      "        if maxtab.size == 0: #how to handle empty np array, which occurs if no events are detected\n",
      "            maxptime = []\n",
      "            maxpeaks = []\n",
      "        \n",
      "        else:\n",
      "            maxptime = maxtab[:,0] #all of the rows and only the first column are time\n",
      "            maxpeaks = maxtab[:,1] #all of the rows and only the second column are amp.\n",
      "\n",
      "        maxptime_true = (np.multiply(maxptime,rate) + time[0]) #get the real time for each peak, since the peak is given in index not time\n",
      "        peak_sets_temp_x[label] = maxptime_true #store array of event time in the dictionary with the ROI name as the key\n",
      "\n",
      "        peak_sets_temp_y[label] = np.array(maxpeaks) #store array of events in the dictionary with the ROI name as the key\n",
      "        #RR = rrinterval(maxptime_true)\n",
      "        peak_amp_temp[label] = Series(data = maxpeaks, index=maxptime_true).describe() #store summary data series in the summary dataframe\n",
      "        #rr_int_temp[label] = Series(data = RR, index=maxptime_true[:-1]).describe()\n",
      "        end_time = t.clock()\n",
      "        print label, 'took', (end_time - start_time), 'seconds to run'\n",
      "    return peak_amp_temp, peak_sets_temp_x, peak_sets_temp_y\n",
      "\n",
      "def line_plots(data_orignal, data_smooth, events_x, events_y, peak_sets_temp_x, peak_sets_temp_y, event_summary,folder):\n",
      "    '''\n",
      "    creates the plots with two lines: original data and smoothed data. it also overlays the events from LCpro and RAIN.\n",
      "    '''\n",
      "    lcpro_events_select_list = event_summary[event_summary['LCpro, select'] >= 1].index.tolist() #list of only roi's found by RAIN\n",
      "    \n",
      "    for label, column in data_orignal.iteritems():\n",
      "        \n",
      "        plt.figure()\n",
      "        plt.xlabel('Time (s)')\n",
      "        plt.ylabel('Intensity')\n",
      "        plt.title(label)\n",
      "        plt.ylim(ymin = min(data_orignal.min()), ymax = max(data_orignal.max()))\n",
      "        plt.xlim(xmin = data_orignal.index[0], xmax = data_orignal.index[-1])\n",
      "        \n",
      "        plt.plot(data_orignal.index, data_orignal[label], label = 'original', color = 'r')\n",
      "        plt.plot(data_orignal.index, data_smooth[label], label = 'smooth', color = 'b')\n",
      "        if label in data_orignal.columns:     \n",
      "            plt.plot(events_x[label], events_y[label], marker = \"^\", color=\"r\", linestyle= \"None\")\n",
      "        if label in lcpro_events_select_list:\n",
      "            plt.plot(events_x[label], events_y[label], marker = \"^\", color=\"g\", linestyle= \"None\")\n",
      "        if label in peak_sets_temp_x.keys():\n",
      "            plt.plot(peak_sets_temp_x[label], peak_sets_temp_y[label], marker = \"^\", color=\"y\", linestyle= \"None\")\n",
      "        plt.savefig(r'%s/plots/%s.pdf' %(folder,label))\n",
      "        plt.close()\n",
      "\n",
      "def rrinterval(maxptime): \n",
      "    \"\"\"\n",
      "    find time from r peak to r peak, called the R-R interval. Input array must be a list of numbers (float).\n",
      "    \"\"\"\n",
      "    \n",
      "    rrint = [] #empty array for ttot to go into\n",
      "    \n",
      "    for time in maxptime[1:]: #for each r peak, starting with the second one\n",
      "        s2time = maxptime.index(time) \n",
      "        s2 = maxptime[s2time-1]\n",
      "        meas = time - s2 #measure the interval by subtracting\n",
      "        rrint.append(meas) #append the measurement to the ttotal array\n",
      "    return rrint #return array\n",
      "\n",
      "print \"Notebook initalized\"    "
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "Notebook initalized\n"
       ]
      }
     ],
     "prompt_number": 1
    },
    {
     "cell_type": "heading",
     "level": 1,
     "metadata": {},
     "source": [
      "Define Folders and File Paths. Import Data and Plot Data."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "results_folder = os.path.join(os.getcwd(), 'NMResults')\n",
      "mkdir_p(results_folder) #if path alread exists, nothing will happen and no message will be displayed"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 2
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "#get datafile list\n",
      "files = os.listdir(results_folder)\n",
      "vfiles = [f for f in files if f[0].lower()=='v']\n",
      "for i in vfiles:\n",
      "    print i"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "voltage-BRSModel-sec0-gL2_3-gnap5_6.txt\n",
        "voltage-BRSModel-sec1320-eL.txt\n",
        "voltage-BRSModel-sec1320-gc-eL-55.txt\n",
        "voltage-BRSModel-sec1320-gc-eL-65.txt\n",
        "voltage-BRSModel-sec1320-gc1_3.txt\n",
        "voltage-BRSModel-sec60-eL-gc0_2.txt\n",
        "voltage-BRSModel-sec60-eL-gc0_5.txt\n",
        "voltage-BRSModel-sec60-eL.txt\n",
        "voltage-gL-BRSModel-sec0-gL2_3-gnap5_6.txt\n",
        "voltage-TBModel-sec1-gc.txt\n",
        "voltage-TBModel-sec1320-gc-eL-55.txt\n",
        "voltage-TBModel-sec1320-gc-eL-65.txt\n",
        "voltage-TBModel-sec1320-IP-gL2_5.txt\n",
        "voltage-TBModel-sec1320-IP-gL2_7.txt\n",
        "voltage-TBModel-sec1320-IP-gL2_9.txt\n",
        "voltage-TBModel-sec1320-IP-gL3_2.txt\n",
        "voltage-TBModel-sec1320-IP-gL3_4.txt\n",
        "voltage-TBModel-sec1320-IP-gL3_6.txt\n",
        "voltage-TBModel-sec1320-IP-gL3_8.txt\n",
        "voltage-TBModel-sec1320-IP-gL4_1.txt\n",
        "voltage-TBModel-sec1320-IP-gL4_3.txt\n",
        "voltage-TBModel-sec1320-IP-gL4_5.txt\n",
        "voltage-TBModel-sec1320-IP-gnaps2_8.txt\n",
        "voltage-TBModel-sec1320-IP-gnaps3_0.txt\n",
        "voltage-TBModel-sec1320-IP-gnaps3_3.txt\n",
        "voltage-TBModel-sec1320-IP-gnaps3_5.txt\n",
        "voltage-TBModel-sec1320-IP-gnaps3_7.txt\n",
        "voltage-TBModel-sec1320-IP-gnaps4_0.txt\n",
        "voltage-TBModel-sec1320-IP-gnaps4_2.txt\n",
        "voltage-TBModel-sec300-IP-gL2_5.txt\n",
        "voltage-TBModel-sec300-IP-gL2_7.txt\n",
        "voltage-TBModel-sec300-IP-gL2_9.txt\n",
        "voltage-TBModel-sec300-IP-gL3_2.txt\n",
        "voltage-TBModel-sec300-IP-gL3_4.txt\n",
        "voltage-TBModel-sec300-IP-gL3_6.txt\n",
        "voltage-TBModel-sec300-IP-gL3_8.txt\n",
        "voltage-TBModel-sec300-IP-gL4_1.txt\n",
        "voltage-TBModel-sec300-IP-gL4_3.txt\n",
        "voltage-TBModel-sec300-IP-gL4_5.txt\n",
        "voltage-TBModel-sec300-IP-gnaps2_8.txt\n",
        "voltage-TBModel-sec300-IP-gnaps3_0.txt\n",
        "voltage-TBModel-sec300-IP-gnaps3_3.txt\n",
        "voltage-TBModel-sec300-IP-gnaps3_5.txt\n",
        "voltage-TBModel-sec300-IP-gnaps3_7.txt\n",
        "voltage-TBModel-sec300-IP-gnaps4_0.txt\n",
        "voltage-TBModel-sec300-IP-gnaps4_2.txt\n",
        "voltage-TBModel-sec60-eL-gc0_2.txt\n",
        "voltage-TBModel-sec60-eL-gc0_5.txt\n",
        "voltage-TBModel-sec60-eL-gc1_0.txt\n",
        "voltage-TBModel-sec60-eL-gc1_5.txt\n",
        "voltage-TBModel-sec60-eL-gc1_8.txt\n",
        "voltage-TBModel-sec60-gc-eL-45.txt\n",
        "voltage-TBModel-sec60-gc-eL-55.txt\n",
        "voltage-TBModel-sec60-gc-eL-65.txt\n",
        "voltage-TBModel-sec60-gc-eL-75.txt\n",
        "voltage-TBModel-sec60-gc-IP0_9.txt\n",
        "voltage-TBModel-sec60-gc-IP0_95.txt\n",
        "voltage-TBModel-sec60-gc-IP1_0.txt\n",
        "voltage-TBModel-sec60-gc-IP1_2.txt\n",
        "voltage-TBModel-sec60-gc0_1-IP0_9.txt\n",
        "voltage-TBModel-sec60-gc1_3-gnaps2_8.txt\n",
        "voltage-TBModel-sec60-gc1_3-gnaps3_0.txt\n",
        "voltage-TBModel-sec60-gc1_3-gnaps3_3.txt\n",
        "voltage-TBModel-sec60-gc1_3-gnaps3_5.txt\n",
        "voltage-TBModel-sec60-gc1_3-gnaps3_7.txt\n",
        "voltage-TBModel-sec60-gc1_3-gnaps4_0.txt\n",
        "voltage-TBModel-sec60-gc1_3-gnaps4_2.txt\n",
        "voltage-TBModel-sec60-gc1_3.txt\n",
        "voltage-TBModel-sec60-gc1_6-gnaps2_8.txt\n",
        "voltage-TBModel-sec60-gc1_6-gnaps3_0.txt\n",
        "voltage-TBModel-sec60-gc1_6-gnaps3_3.txt\n",
        "voltage-TBModel-sec60-gc1_6-gnaps3_5.txt\n",
        "voltage-TBModel-sec60-gc1_6-gnaps3_7.txt\n",
        "voltage-TBModel-sec60-gc1_6-gnaps4_0.txt\n",
        "voltage-TBModel-sec60-gc1_6-gnaps4_2.txt\n",
        "voltage-TBModel-sec60-gnaps2_8-gc6.txt\n",
        "voltage-TBModel-sec60-gnaps3_0-gc6.txt\n",
        "voltage-TBModel-sec60-gnaps3_3-gc6.txt\n",
        "voltage-TBModel-sec60-gnaps3_5-gc6.txt\n",
        "voltage-TBModel-sec60-gnaps3_7-gc6.txt\n",
        "voltage-TBModel-sec60-gnaps4_0-gc6.txt\n",
        "voltage-TBModel-sec60-gnaps4_2-gc6.txt\n",
        "voltage-TBModel-sec60-IP-gL2_5.txt\n",
        "voltage-TBModel-sec60-IP-gL2_7.txt\n",
        "voltage-TBModel-sec60-IP-gL2_9.txt\n",
        "voltage-TBModel-sec60-IP-gL3_2.txt\n",
        "voltage-TBModel-sec60-IP-gL3_4.txt\n",
        "voltage-TBModel-sec60-IP-gL3_6.txt\n",
        "voltage-TBModel-sec60-IP-gL3_8.txt\n",
        "voltage-TBModel-sec60-IP-gL4_1.txt\n",
        "voltage-TBModel-sec60-IP-gL4_3.txt\n",
        "voltage-TBModel-sec60-IP-gL4_5.txt\n",
        "voltage-TBModel-sec60-IP-gNaP2_8.txt\n",
        "voltage-TBModel-sec60-IP-gNaP3_0.txt\n",
        "voltage-TBModel-sec60-IP-gNaP3_3.txt\n",
        "voltage-TBModel-sec60-IP-gNaP3_5.txt\n",
        "voltage-TBModel-sec60-IP-gNaP3_7.txt\n",
        "voltage-TBModel-sec60-IP-gNaP4_0.txt\n",
        "voltage-TBModel-sec60-IP-gNaP4_2.txt\n",
        "voltage-TBModel-sec60-IP-gnaps2_8.txt\n",
        "voltage-TBModel-sec60-IP-gnaps3_0.txt\n",
        "voltage-TBModel-sec60-IP-gnaps3_3.txt\n",
        "voltage-TBModel-sec60-IP-gnaps3_5.txt\n",
        "voltage-TBModel-sec60-IP-gnaps3_7.txt\n",
        "voltage-TBModel-sec60-IP-gnaps4_0.txt\n",
        "voltage-TBModel-sec60-IP-gnaps4_2.txt\n",
        "voltage-TBModel-sec60-IP0_9-gc1_6.txt\n",
        "voltage-TBModel-sec60-IP0_9.txt\n",
        "voltage-TBModel-sec60-IP0_95-gc1_6.txt\n",
        "voltage-TBModel-sec60-IP1_0-gc1_6.txt\n",
        "voltage-TBModel-sec60-IP1_2-gc1_6.txt\n"
       ]
      }
     ],
     "prompt_number": 3
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "#specify data file, find it and extract experiment information from its name\n",
      "\n",
      "#'voltage-BRSModel-sec1320-gc-eL-55.txt'\n",
      "data_file = 'voltage-BRSModel-sec1320-eL.txt'\n",
      "File_Path = os.path.join(results_folder, data_file)\n",
      "if not os.path.isfile(File_Path):\n",
      "    print \"Cannot find file\",data_file\n",
      "else:\n",
      "    file_info = data_file.partition('.')[0].split(\"-\")\n",
      "    if results_folder:\n",
      "                subfolder= NMResources.make_folderpaths(Model.__name__, sim_dataframe.index[-1], custom_params, results_folder)\n",
      "            else:\n",
      "                subfolder = NMResources.make_folderpaths(Model.__name__, sim_dataframe.index[-1], custom_params, os.getcwd())\n",
      "            utility.mkdir_p(subfolder)\n",
      "\n",
      "variable = file_info[3]\n",
      "file_info"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 4,
       "text": [
        "['voltage', 'BRSModel', 'sec1320', 'eL']"
       ]
      }
     ],
     "prompt_number": 4
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "#read-in file and reset output dict\n",
      "data_raw = pd.read_csv(File_Path, index_col= 0)\n",
      "\n",
      "output_dict = {} # reset output dict each time I load a new data file\n",
      "plot_dict={}\n",
      "\n",
      "output_dict['File_Path'] = File_Path"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 5
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "plot_ext = \".png\"\n",
      "data_ext = \".txt\""
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 6
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "#construct output directory path name and part of file name for plots and data files\n",
      "output_directory = os.path.join(os.getcwd(), 'NMAnalysis')\n",
      "exp_info = \"-\".join(file_info[1:])\n",
      "output_suffix = exp_info + data_ext\n",
      "plot_suffix = exp_info + plot_ext\n",
      "#output_directory = \"/Users/mfinemorris/Desktop/Neuron Modeling\"\n",
      "mkdir_p(output_directory)\n",
      "output_suffix, plot_suffix"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 7,
       "text": [
        "('BRSModel-sec1320-eL.txt', 'BRSModel-sec1320-eL.png')"
       ]
      }
     ],
     "prompt_number": 7
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "data_raw.columns.values"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 54,
       "text": [
        "array(['-55', '-60', '-65'], dtype=object)"
       ]
      }
     ],
     "prompt_number": 54
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "meas = '2.8'\n",
      "plt.plot(data_raw.index, data_raw[meas])\n",
      "plt.show()"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "#plot all raw data time series\n",
      "for label, column in data_raw.iteritems():\n",
      "    \n",
      "    plt.plot(data_raw.index, column)\n",
      "    plt.title(label)\n",
      "    plt.show()"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 55
    },
    {
     "cell_type": "heading",
     "level": 1,
     "metadata": {},
     "source": [
      "Process Data"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# calc rate\n",
      "rate = data_raw.index[3] - data_raw.index[2]\n",
      "rate\n",
      "output_dict['rate'] = rate"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 57
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# make experiment label\n",
      "\n",
      "exp = (file_info[1]+\" with \"+\", \".join(file_info[2:])).replace(\"_\",\".\")\n",
      "output_dict['exp'] = exp\n",
      "exp"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 58,
       "text": [
        "'BRSModel with sec1320, eL'"
       ]
      }
     ],
     "prompt_number": 58
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "#event detection on all time series\n",
      "delta = 1\n",
      "peak_amp_temp, peak_sets_temp_x, peak_sets_temp_y = event_detection(data_raw, delta, rate)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "-55 took 22.1259454044 seconds to run\n",
        "-60"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " took 19.283872112 seconds to run\n",
        "-65"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " took 17.3540903752 seconds to run\n"
       ]
      }
     ],
     "prompt_number": 59
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "peak_sets_temp_x"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 60,
       "text": [
        "{'-55': array([  4.42100033e+02,   7.14400054e+02,   9.81000074e+02, ...,\n",
        "          1.31928730e+06,   1.31955130e+06,   1.31981540e+06]),\n",
        " '-60': array([    8643.90065484,     8661.00065614,     8678.90065749, ...,\n",
        "         1318557.79989074,  1318600.19989395,  1318676.19989971]),\n",
        " '-65': array([ 0.])}"
       ]
      }
     ],
     "prompt_number": 60
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "#index/cols for the peak array that will be saved to file\n",
      "cols=pd.MultiIndex.from_product([data_raw.columns,[u'rr', u'x', u'y']],names=['variable','peak_data'])\n",
      "cols"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 61,
       "text": [
        "MultiIndex(levels=[[u'-55', u'-60', u'-65'], [u'rr', u'x', u'y']],\n",
        "           labels=[[0, 0, 0, 1, 1, 1, 2, 2, 2], [0, 1, 2, 0, 1, 2, 0, 1, 2]],\n",
        "           names=[u'variable', u'peak_data'])"
       ]
      }
     ],
     "prompt_number": 61
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "#save peak data for later operations in notebook\n",
      "peaks = {} \n",
      "\n",
      "#save peak data for later output\n",
      "peak_y = peak_sets_temp_y\n",
      "peak_x = peak_sets_temp_x\n",
      "temp = []\n",
      "\n",
      "max_peaks = max([len(peak_x[key]) for key in peak_x])\n",
      "\n",
      "for k in peak_x:\n",
      "    start_time = t.clock()\n",
      "\n",
      "    #### Collect peak data for later notebook operations\n",
      "    xlist = peak_x[k].tolist()\n",
      "    #get RR interval\n",
      "    RR = rrinterval(xlist)\n",
      "    RR.append(NaN)\n",
      "    peaks[k] = DataFrame({'Amplitude':peak_y[k].tolist(),'Interval':RR}, index = xlist)\n",
      "\n",
      "    #### Collect peak data for saving\n",
      "    temp.append(peak_x[k])\n",
      "    temp.append(peak_y[k])\n",
      "    temp.append(RR[:-1])\n",
      "    \n",
      "    end_time = t.clock()\n",
      "    print k, \"finished in\", np.round(end_time - start_time, 3)\n",
      "    \n",
      "peak_x_y = pd.DataFrame(data=temp, index=cols, columns=range(0,max_peaks)).T.to_sparse()\n",
      "\n",
      "output_dict['peak_amp_temp'] = peak_amp_temp\n",
      "#output_dict['peaks_'] = peak_x_y"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "-55 finished in 0.308\n",
        "-60"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " finished in 0.116\n",
        "-65 finished in 0.0\n"
       ]
      }
     ],
     "prompt_number": 62
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "save_file = os.path.join(output_directory,'peaks-'+output_suffix)\n",
      "print save_file\n",
      "# IDK why this works and peak_x_y.to_csv() doesn't, but you can't argue with results...\n",
      "peak_dict = peak_x_y.to_dict()\n",
      "pd.DataFrame().from_dict(peak_dict).to_csv(save_file)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "C:\\Users\\mfinemorris\\repos\\WilsonLab\\NMAnalysis\\peaks-BRSModel-sec1320-eL.txt\n"
       ]
      }
     ],
     "prompt_number": 63
    },
    {
     "cell_type": "heading",
     "level": 4,
     "metadata": {},
     "source": [
      "peak to peak measurments, includes ibi"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "#how many peaks occur in each trace?\n",
      "for key, value in peak_sets_temp_x.iteritems():\n",
      "    v = value.tolist()\n",
      "    print key, '=', len(v)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "-55 = 4998\n",
        "-60 = 3780\n",
        "-65 = 1\n"
       ]
      }
     ],
     "prompt_number": 64
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "#all events detected\n",
      "peaks = {}\n",
      "for key, value in peak_sets_temp_x.iteritems():\n",
      "    start_time = t.clock()\n",
      "    peak_x = value.tolist()\n",
      "    peak_y = peak_sets_temp_y[key].tolist()\n",
      "    \n",
      "    RR = rrinterval(peak_x)\n",
      "    RR.append(NaN)\n",
      "    #make Dataframe with index as peak_x (time of peak) and store amplitude of peak(peak_y) and RR-interval\n",
      "    results_peaks = DataFrame({'Amplitude':peak_y,'Interval':RR}, index = peak_x)  \n",
      "    peaks[key] = results_peaks\n",
      "    end_time = t.clock()\n",
      "    print key, \"finished in\", np.round(end_time - start_time, 3)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "-55 finished in 0.193\n",
        "-60"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " finished in 0.107\n",
        "-65 finished in 0.0\n"
       ]
      }
     ],
     "prompt_number": 65
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "peaks"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 66,
       "text": [
        "{'-55':                 Amplitude    Interval\n",
        " 442.100033       6.033314  272.300021\n",
        " 714.400054       5.989792  266.600020\n",
        " 981.000074       5.933781  264.800020\n",
        " 1245.800094      6.002457  264.300020\n",
        " 1510.100114      5.997982  264.100020\n",
        " 1774.200134      5.901916  264.100020\n",
        " 2038.300154      6.033662  264.000020\n",
        " 2302.300174      5.895652  264.100020\n",
        " 2566.400194      5.990996  264.000020\n",
        " 2830.400214      6.029177  264.000020\n",
        " 3094.400234      5.920262  264.100020\n",
        " 3358.500254      5.966214  264.000020\n",
        " 3622.500274      6.033895  264.000020\n",
        " 3886.500294      5.962350  264.100020\n",
        " 4150.600314      5.926207  264.000020\n",
        " 4414.600334      6.029593  264.000020\n",
        " 4678.600354      5.993290  264.100020\n",
        " 4942.700374      5.874905  264.000020\n",
        " 5206.700394      6.015055  264.000020\n",
        " 5470.700414      6.018484  264.000020\n",
        " 5734.700434      5.875881  264.100020\n",
        " 5998.800454      5.990127  264.000020\n",
        " 6262.800474      6.030584  264.000020\n",
        " 6526.800494      5.928085  264.100020\n",
        " 6790.900514      5.956394  264.000020\n",
        " 7054.900534      6.033746  264.000020\n",
        " 7318.900554      5.970763  264.100020\n",
        " 7583.000574      5.915979  264.000020\n",
        " 7847.000594      6.027359  264.000020\n",
        " 8111.000614      6.000936  264.100020\n",
        " ...                   ...         ...\n",
        " 1312158.499406   6.020496  264.000020\n",
        " 1312422.499426   6.012467  264.000020\n",
        " 1312686.499446   5.857120  264.100020\n",
        " 1312950.599466   5.999905  264.000020\n",
        " 1313214.599486   6.028153  264.000020\n",
        " 1313478.599506   5.912483  264.100020\n",
        " 1313742.699526   5.967844  264.000020\n",
        " 1314006.699546   6.033831  264.000020\n",
        " 1314270.699566   5.957089  264.100020\n",
        " 1314534.799586   5.930848  264.000020\n",
        " 1314798.799606   6.030285  264.000020\n",
        " 1315062.799626   5.993219  264.100020\n",
        " 1315326.899646   5.878299  264.000020\n",
        " 1315590.899666   6.016609  264.000020\n",
        " 1315854.899686   6.016752  264.000020\n",
        " 1316118.899706   5.869964  264.100020\n",
        " 1316382.999726   5.993800  264.000020\n",
        " 1316646.999746   6.030191  264.000020\n",
        " 1316910.999766   5.926764  264.100020\n",
        " 1317175.099786   5.959197  264.000020\n",
        " 1317439.099806   6.033810  264.000020\n",
        " 1317703.099826   5.967121  264.100020\n",
        " 1317967.199846   5.918969  264.000020\n",
        " 1318231.199866   6.028556  264.000020\n",
        " 1318495.199886   5.996174  264.100020\n",
        " 1318759.299906   5.870353  264.000020\n",
        " 1319023.299926   6.013760  264.000020\n",
        " 1319287.299946   6.019563  264.000020\n",
        " 1319551.299966   5.879235  264.100020\n",
        " 1319815.399986   5.989314         NaN\n",
        " \n",
        " [4998 rows x 2 columns], '-60':                 Amplitude     Interval\n",
        " 8643.900655      6.348122    17.100001\n",
        " 8661.000656      6.263814    17.900001\n",
        " 8678.900657      6.445204    18.600001\n",
        " 8697.500659      6.304049    19.600001\n",
        " 8717.100660      6.410725    20.600002\n",
        " 8737.700662      6.262941    21.700002\n",
        " 8759.400664      6.354858    23.200002\n",
        " 8782.600665      6.279868    25.000002\n",
        " 8807.600667      6.395483    27.200002\n",
        " 8834.800669      6.386804    30.200002\n",
        " 8865.000672      6.369626    34.600003\n",
        " 8899.600674      6.310864    42.400003\n",
        " 8942.000677      6.298875    76.000006\n",
        " 9018.000683      6.226181  4494.500340\n",
        " 13512.501024     6.449337    17.200001\n",
        " 13529.701025     6.358525    17.800001\n",
        " 13547.501026     6.419473    18.700001\n",
        " 13566.201028     6.321173    19.500001\n",
        " 13585.701029     6.437847    20.600002\n",
        " 13606.301031     6.367401    21.700002\n",
        " 13628.001032     6.240804    23.300002\n",
        " 13651.301034     6.285211    24.900002\n",
        " 13676.201036     6.344840    27.200002\n",
        " 13703.401038     6.346509    30.200002\n",
        " 13733.601040     6.368722    34.600003\n",
        " 13768.201043     6.358437    42.400003\n",
        " 13810.601046     6.345778    76.000006\n",
        " 13886.601052     6.302872  4494.500340\n",
        " 18381.101393     6.491607    17.200001\n",
        " 18398.301394     6.413774    17.800001\n",
        " ...                   ...          ...\n",
        " 1308862.999156   6.343173    76.000006\n",
        " 1308938.999162   6.335811  4494.500340\n",
        " 1313433.499503   6.503449    17.200001\n",
        " 1313450.699504   6.446413    17.900001\n",
        " 1313468.599505   6.268553    18.600001\n",
        " 1313487.199507   6.439431    19.500001\n",
        " 1313506.699508   6.349744    20.600002\n",
        " 1313527.299510   6.429148    21.800002\n",
        " 1313549.099511   6.394468    23.200002\n",
        " 1313572.299513   6.407701    25.000002\n",
        " 1313597.299515   6.279639    27.200002\n",
        " 1313624.499517   6.246063    30.100002\n",
        " 1313654.599519   6.228359    34.600003\n",
        " 1313689.199522   6.309953    42.400003\n",
        " 1313731.599525   6.295343    76.000006\n",
        " 1313807.599531   6.317464  4494.500340\n",
        " 1318302.099871   6.460800    17.200001\n",
        " 1318319.299873   6.423008    17.900001\n",
        " 1318337.199874   6.372549    18.600001\n",
        " 1318355.799875   6.432937    19.600001\n",
        " 1318375.399877   6.255661    20.500002\n",
        " 1318395.899878   6.391349    21.800002\n",
        " 1318417.699880   6.422027    23.200002\n",
        " 1318440.899882   6.403802    25.000002\n",
        " 1318465.899884   6.362237    27.200002\n",
        " 1318493.099886   6.337385    30.200002\n",
        " 1318523.299888   6.258749    34.500003\n",
        " 1318557.799891   6.211895    42.400003\n",
        " 1318600.199894   6.195890    76.000006\n",
        " 1318676.199900   6.248793          NaN\n",
        " \n",
        " [3780 rows x 2 columns], '-65':    Amplitude  Interval\n",
        " 0        -60       NaN}"
       ]
      }
     ],
     "prompt_number": 66
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "#interburst interval detection\n",
      "ibi_thresh = 200 #in ms #!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!\n",
      "ibi_average = Series(index = data_raw.columns)\n",
      "ibi_std = Series(index = data_raw.columns)\n",
      "for key, value in peaks.iteritems():\n",
      "    ibi = value[value['Interval']>ibi_thresh].Interval.mean()\n",
      "    ibi_average[key] = ibi\n",
      "    \n",
      "    std = value[value['Interval']>ibi_thresh].Interval.std()\n",
      "    ibi_std[key] = std\n",
      "    \n",
      "ibi_data = pd.concat({'ibi_average':ibi_average,'ibi_std':ibi_std}, axis=1)\n",
      "\n",
      "output_dict['ibi_thresh'] = ibi_thresh\n",
      "#output_dict['ibi_average'] = ibi_average\n",
      "#output_dict['ibi_std'] = ibi_std\n",
      "\n",
      "output_dict['ibi_avg_std']=ibi_data\n",
      "'''\n",
      "save_file = os.path.join(output_directory,'ibi-'+output_suffix)\n",
      "df = pd.DataFrame().from_dict(ibi_data.to_dict())\n",
      "df.to_csv(save_file)\n",
      "'''\n",
      "print ibi_thresh\n",
      "ibi_data"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "200\n"
       ]
      },
      {
       "html": [
        "<div style=\"max-height:1000px;max-width:1500px;overflow:auto;\">\n",
        "<table border=\"1\" class=\"dataframe\">\n",
        "  <thead>\n",
        "    <tr style=\"text-align: right;\">\n",
        "      <th></th>\n",
        "      <th>ibi_average</th>\n",
        "      <th>ibi_std</th>\n",
        "    </tr>\n",
        "  </thead>\n",
        "  <tbody>\n",
        "    <tr>\n",
        "      <th>-55</th>\n",
        "      <td>  264.033080</td>\n",
        "      <td> 0.131383</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>-60</th>\n",
        "      <td> 4494.509262</td>\n",
        "      <td> 0.028560</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>-65</th>\n",
        "      <td>         NaN</td>\n",
        "      <td>      NaN</td>\n",
        "    </tr>\n",
        "  </tbody>\n",
        "</table>\n",
        "</div>"
       ],
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 67,
       "text": [
        "     ibi_average   ibi_std\n",
        "-55   264.033080  0.131383\n",
        "-60  4494.509262  0.028560\n",
        "-65          NaN       NaN"
       ]
      }
     ],
     "prompt_number": 67
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "#ibi summary graph\n",
      "plt.errorbar(ibi_average.index, ibi_average, ibi_std, marker = '^', color = 'k')\n",
      "#plt.xlim(xmin = 0)\n",
      "plt.xlabel('%s' %(exp))\n",
      "plt.ylabel('Interburst Interval (ms)')\n",
      "plt.title('Interburst interval when %s is changed' %exp)\n",
      "plot_dict['ibi_summary'] = plt.gca()\n",
      "plt.show()"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 72
    },
    {
     "cell_type": "heading",
     "level": 4,
     "metadata": {},
     "source": [
      "burst duration"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "bursts = {}\n",
      "burst_arr = []\n",
      "duration = Series(index = data_raw.columns)\n",
      "duration_std = Series(index = data_raw.columns)\n",
      "burst_ibi = Series(index = data_raw.columns)\n",
      "burst_ibi_std = Series(index = data_raw.columns)\n",
      "\n",
      "for key, value in peaks.iteritems():\n",
      "    b_start = []\n",
      "    b_end = []\n",
      "    b_ibi = []\n",
      "    try:\n",
      "        b_start.append(value.index[0])\n",
      "    except IndexError as e:\n",
      "        continue\n",
      "        \n",
      "    b_flag = True\n",
      "\n",
      "    for index, row in value['Interval'].iteritems():\n",
      "        if b_flag == False:\n",
      "            b_start.append(index)\n",
      "            b_flag = True\n",
      "\n",
      "        if b_flag == True:\n",
      "            if row>ibi_thresh:\n",
      "                b_end.append(index)\n",
      "                b_ibi.append(row)\n",
      "                b_flag = False\n",
      "                \n",
      "    if len(b_start) == len(b_end) +1:\n",
      "        del b_start[-1]\n",
      "        \n",
      "    #store info about bursts\n",
      "    Burst = DataFrame(data = {'Start':b_start})\n",
      "    Burst['End'] = b_end\n",
      "    Burst['Duration'] = Burst['End'] - Burst['Start']\n",
      "    Burst['Burst Interval'] = b_ibi\n",
      "    bursts[key] = Burst\n",
      "    \n",
      "    burst_arr.append(b_start)\n",
      "    burst_arr.append(b_end)\n",
      "    burst_arr.append(Burst['Duration'].values.tolist())\n",
      "    burst_arr.append(b_ibi)\n",
      "\n",
      "    \n",
      "    #information derived from burst indo\n",
      "    duration[key] = Burst['Duration'].mean()\n",
      "    duration_std[key] = Burst['Duration'].std()\n",
      "    burst_ibi[key] =  Burst['Burst Interval'].mean()\n",
      "    burst_ibi_std[key] = Burst['Burst Interval'].std()\n",
      "    \n",
      "\n",
      "#store the burst duration- and ibi- mean and std together in prep for final output\n",
      "burst_misc_data = pd.concat([duration, duration_std, burst_ibi, burst_ibi_std],keys=['duration mean','duration std','ibi mean', 'ibi std'], axis=1)#DataFrame(data =,index = data_raw.columns, )\n",
      "#output_dict['bursts_']=bursts\n",
      "output_dict['burst_stat_data'] = burst_misc_data\n",
      "\n",
      "#burst_misc_data"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 69
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "#save bursts\n",
      "save_file = os.path.join(output_directory,'bursts-'+output_suffix)\n",
      "print save_file\n",
      "\n",
      "# IDK why this works when .to_csv doesn't, but you can't argue with results...\n",
      "burst_ind = pd.MultiIndex.from_product([bursts.keys(), [u'start', u'end', u'duration', u'burst interval']], names=['variable','burst data'])\n",
      "burst_df = pd.DataFrame(data=burst_arr, index=burst_ind).T.to_sparse()\n",
      "burst_dict = burst_df.to_dict()\n",
      "pd.DataFrame().from_dict(burst_dict).to_csv(save_file)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "C:\\Users\\mfinemorris\\repos\\WilsonLab\\NMAnalysis\\bursts-BRSModel-sec1320-eL.txt\n"
       ]
      }
     ],
     "prompt_number": 70
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "file_info"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 57,
       "text": [
        "['voltage', 'TBModel', 'sec300', 'IP', 'gL2_5']"
       ]
      }
     ],
     "prompt_number": 57
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "#burst duration summary plot\n",
      "plt.errorbar(duration.index, duration, duration_std, marker = '^')\n",
      "plt.xlabel('%s' %(variable))\n",
      "plt.ylabel('Burst Duration (ms)')\n",
      "plt.title('Burst duration when %s is changed' %(variable))\n",
      "plot_file = os.path.join(output_directory,\"burst_dur_summary-\"+plot_suffix)\n",
      "print plot_file\n",
      "plt.savefig(plot_file)\n",
      "plt.show()"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "C:\\Users\\mfinemorris\\repos\\WilsonLab\\NMAnalysis\\burst_dur_summary-BRSModel-sec1320-eL.png\n"
       ]
      }
     ],
     "prompt_number": 71
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "#raster plot\n",
      "for key, value in peak_sets_temp_x.iteritems():\n",
      "    key = float(key)\n",
      "    temp_y = []\n",
      "    for n in value:\n",
      "        temp_y.append(key)\n",
      "    plt.plot(value, temp_y, marker = '.', color = 'k', linestyle = 'None', markersize = 2)\n",
      "plt.xlabel('Time (ms)')\n",
      "plt.ylabel('%s' %variable)\n",
      "y_min = float(peak_sets_temp_x.keys()[0])\n",
      "y_max = float(peak_sets_temp_x.keys()[-1])\n",
      "y_diff = (y_max-y_min)/5\n",
      "plt.ylim(ymin=y_min*(1-y_diff), ymax=y_max*(1+y_diff))\n",
      "plt.xlim(xmin = 30000, xmax = 45000)\n",
      "plt.title('Raster plot: %s'%exp)\n",
      "plot_file = os.path.join(output_directory,\"raster-\"+plot_suffix)\n",
      "print plot_file\n",
      "plt.savefig(plot_file)\n",
      "plt.show()"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "C:\\Users\\mfinemorris\\repos\\WilsonLab\\NMAnalysis\\raster-BRSModel-sec1320-eL.png\n"
       ]
      }
     ],
     "prompt_number": 75
    },
    {
     "cell_type": "heading",
     "level": 2,
     "metadata": {},
     "source": [
      "Freq plots"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "import math"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 76
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "key = '1.0' #must be a string "
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 77
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "rris = {}\n",
      "for key in peaks:\n",
      "    rri = peaks[key]['Interval'].tolist()\n",
      "    try:\n",
      "        del rri[-1] #the last value is NaN, so we delete it.\n",
      "    except IndexError:\n",
      "        continue\n",
      "\n",
      "    rri_new = []\n",
      "    for i in rri:\n",
      "        bpm = 60000/i\n",
      "        rri_new.append(bpm)\n",
      "    time_int = peaks[key].index.tolist()\n",
      "    del time_int[-1] #must be the same length as rri\n",
      "\n",
      "    plt.ylabel('Event Rate (events/min.)')\n",
      "    plt.xlabel('Time (s)')\n",
      "    plt.title('Event Freqency-Peak detection')\n",
      "    plt.plot(time_int, rri_new)\n",
      "    plt.show()\n",
      "    ser = pd.Series(data=rri_new, index=time_int)\n",
      "    rris[key] = ser\n",
      "    \n",
      "#output_dict['rris_'] = rris"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 78
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "save_file = os.path.join(output_directory,'rris-'+output_suffix)\n",
      "print save_file\n",
      "pd.DataFrame().from_dict(rris).to_csv(save_file)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "C:\\Users\\mfinemorris\\repos\\WilsonLab\\NMAnalysis\\rris-BRSModel-sec1320-eL.txt\n"
       ]
      }
     ],
     "prompt_number": 79
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "def sliding_peak_freq(dictionary, data_raw, window):\n",
      "    '''\n",
      "    takes a window size in ms and does non-overlapping count (which is freq, since the windows are all the same size) and average ibi. \n",
      "    returns two dataframes with this information for each 'test' case.\n",
      "    '''\n",
      "    import math\n",
      "    num = math.trunc(data_raw.index[-1]/window) #get the number of windows to do the counts and averages over.\n",
      "    \n",
      "    sliding_count = DataFrame(index= (np.arange(num)*window)) #where we're storing the results for each timeseries\n",
      "    sliding_mean = DataFrame(index= (np.arange(num)*window)) #where we're storing the results for each timeseries\n",
      "    \n",
      "    for key, value in dictionary.iteritems():\n",
      "        \n",
      "        temp_count = Series(index= (np.arange(num)*window)) #temp storage\n",
      "        temp_mean = Series(index= (np.arange(num)*window)) #temp storage\n",
      "        \n",
      "        for i in (np.arange(num)*window):\n",
      "            temp_count[i] = value['Interval'][i:(i+window)].count() #get the count in the window\n",
      "            temp_mean[i] = value['Interval'][i:(i+window)].mean() #get the mean in the window\n",
      "        \n",
      "        temp_mean = temp_mean.fillna(0) #temp mean returns NaN for windows with no events. make it zero for graphing\n",
      "        \n",
      "        sliding_count[key] = temp_count #store series in results table\n",
      "        sliding_mean[key] = temp_mean #store series in results table\n",
      "    \n",
      "    sliding_count = sliding_count.sort_index(axis = 1)\n",
      "    sliding_mean = sliding_mean.sort_index(axis = 1) #my attempt at reordering so the columns are in increaing order\n",
      "    return sliding_mean, sliding_count\n",
      "\n",
      "\n",
      "def sliding_burst_freq(dictionary, data_raw, window):\n",
      "    '''\n",
      "    takes a window size in ms and does non-overlapping count (which is freq, since the windows are all the same size) and average ibi. \n",
      "    returns two dataframes with this information for each 'test' case.\n",
      "    '''\n",
      "    \n",
      "    import math\n",
      "    num = math.trunc(data_raw.index[-1]/window) #get the number of windows to do the counts and averages over.\n",
      "    \n",
      "    sliding_count = DataFrame(index= (np.arange(num)*window)) #where we're storing the results for each timeseries\n",
      "    sliding_mean_dur = DataFrame(index= (np.arange(num)*window)) #where we're storing the results for each timeseries\n",
      "    sliding_mean_dur = DataFrame(index= (np.arange(num)*window))\n",
      "    \n",
      "    for key, value in dictionary.iteritems():\n",
      "        \n",
      "        temp_count = Series(index= (np.arange(num)*window)) #temp storage\n",
      "        temp_mean_dur = Series(index= (np.arange(num)*window)) #temp storage\n",
      "        \n",
      "        for i in (np.arange(num)*window):\n",
      "            temp_count[i] = value['Duration'][i:(i+window)].count() #get the count in the window\n",
      "            temp_mean_dur[i] = value['Duration'][i:(i+window)].mean() #get the mean in the window\n",
      "        \n",
      "        temp_mean = temp_mean_dur.fillna(0) #temp mean returns NaN for windows with no events. make it zero for graphing\n",
      "        \n",
      "        sliding_count[key] = temp_count #store series in results table\n",
      "        sliding_mean_dur[key] = temp_mean #store series in results table\n",
      "    \n",
      "    sliding_count = sliding_count.sort_index(axis = 1)\n",
      "    sliding_mean = sliding_mean_dur.sort_index(axis = 1) #my attempt at reordering so the columns are in increaing order\n",
      "    return sliding_mean, sliding_count"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 80
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "window = 1000 #set window size, no overlap"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 81
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "sliding_p_mean, sliding_p_count = sliding_peak_freq(peaks, data_raw,  window = window)\n",
      "#output_dict['sliding_p_mean_'] = sliding_p_mean\n",
      "#output_dict['sliding_p_count_'] = sliding_p_count\n",
      "peak_c_m = pd.concat({'peak count':sliding_p_count, 'peak mean':sliding_p_mean}, axis=1).to_sparse()\n",
      "#output_dict['sliding_peaks_']=peak_c_m"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 82
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "sliding_b_mean, sliding_b_count = sliding_burst_freq(bursts, data_raw,  window = window)\n",
      "#output_dict['sliding_b_count_'] = sliding_b_count\n",
      "#output_dict['sliding_b_mean_'] = sliding_b_mean\n",
      "burst_c_m = pd.concat({'burst count':sliding_b_count, 'burst mean':sliding_b_mean}, axis=1).to_sparse()\n",
      "#output_dict['sliding_bursts_']=burst_c_m"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 83
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "save_file = os.path.join(output_directory,'sliding_burst_cm-'+output_suffix)\n",
      "print save_file\n",
      "pd.DataFrame().from_dict(burst_c_m.to_dict()).to_csv(save_file)\n",
      "\n",
      "save_file = os.path.join(output_directory,'sliding_peak_cm-'+output_suffix)\n",
      "print save_file\n",
      "pd.DataFrame().from_dict(peak_c_m.to_dict()).to_csv(save_file)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "C:\\Users\\mfinemorris\\repos\\WilsonLab\\NMAnalysis\\sliding_burst_cm-BRSModel-sec1320-eL.txt\n",
        "C:\\Users\\mfinemorris\\repos\\WilsonLab\\NMAnalysis\\sliding_peak_cm-BRSModel-sec1320-eL.txt"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n"
       ]
      }
     ],
     "prompt_number": 84
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "#save sliding data"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "#quick sharex plot of count and raw data for a given test varible \n",
      "foo = '0.95'\n",
      "fig, ax = plt.subplots(2, sharex= True)\n",
      "ax[0].plot(data_raw.index, data_raw[foo])\n",
      "ax[1].plot(sliding_p_count.index, sliding_p_count[foo], marker = '.')\n",
      "fig.subplots_adjust(hspace = 0.1)\n",
      "plt.show()"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "ename": "KeyError",
       "evalue": "'0.95'",
       "output_type": "pyerr",
       "traceback": [
        "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m\n\u001b[1;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
        "\u001b[1;32m<ipython-input-85-5de7332b2750>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[0mfoo\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;34m'0.95'\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[0mfig\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0max\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mplt\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msubplots\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m2\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msharex\u001b[0m\u001b[1;33m=\u001b[0m \u001b[0mTrue\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 4\u001b[1;33m \u001b[0max\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mplot\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdata_raw\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mindex\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdata_raw\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mfoo\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      5\u001b[0m \u001b[0max\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mplot\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msliding_p_count\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mindex\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msliding_p_count\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mfoo\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmarker\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;34m'.'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      6\u001b[0m \u001b[0mfig\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msubplots_adjust\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mhspace\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;36m0.1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
        "\u001b[1;32mC:\\Users\\mfinemorris\\AppData\\Local\\Enthought\\Canopy\\User\\lib\\site-packages\\pandas\\core\\frame.pyc\u001b[0m in \u001b[0;36m__getitem__\u001b[1;34m(self, key)\u001b[0m\n\u001b[0;32m   1741\u001b[0m             \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_getitem_multilevel\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1742\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1743\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_getitem_column\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1744\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1745\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m_getitem_column\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkey\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
        "\u001b[1;32mC:\\Users\\mfinemorris\\AppData\\Local\\Enthought\\Canopy\\User\\lib\\site-packages\\pandas\\core\\frame.pyc\u001b[0m in \u001b[0;36m_getitem_column\u001b[1;34m(self, key)\u001b[0m\n\u001b[0;32m   1748\u001b[0m         \u001b[1;31m# get column\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1749\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mis_unique\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1750\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_get_item_cache\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1751\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1752\u001b[0m         \u001b[1;31m# duplicate columns & possible reduce dimensionaility\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
        "\u001b[1;32mC:\\Users\\mfinemorris\\AppData\\Local\\Enthought\\Canopy\\User\\lib\\site-packages\\pandas\\core\\generic.pyc\u001b[0m in \u001b[0;36m_get_item_cache\u001b[1;34m(self, item)\u001b[0m\n\u001b[0;32m   1056\u001b[0m         \u001b[0mres\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcache\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mitem\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1057\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mres\u001b[0m \u001b[1;32mis\u001b[0m \u001b[0mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1058\u001b[1;33m             \u001b[0mvalues\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_data\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mitem\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1059\u001b[0m             \u001b[0mres\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_box_item_values\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mitem\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mvalues\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1060\u001b[0m             \u001b[0mcache\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mitem\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mres\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
        "\u001b[1;32mC:\\Users\\mfinemorris\\AppData\\Local\\Enthought\\Canopy\\User\\lib\\site-packages\\pandas\\core\\internals.pyc\u001b[0m in \u001b[0;36mget\u001b[1;34m(self, item, fastpath)\u001b[0m\n\u001b[0;32m   2804\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2805\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0misnull\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mitem\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 2806\u001b[1;33m                 \u001b[0mloc\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mitems\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget_loc\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mitem\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   2807\u001b[0m             \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2808\u001b[0m                 \u001b[0mindexer\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0marange\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mitems\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0misnull\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mitems\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
        "\u001b[1;32mC:\\Users\\mfinemorris\\AppData\\Local\\Enthought\\Canopy\\User\\lib\\site-packages\\pandas\\core\\index.pyc\u001b[0m in \u001b[0;36mget_loc\u001b[1;34m(self, key)\u001b[0m\n\u001b[0;32m   1383\u001b[0m         \u001b[0mloc\u001b[0m \u001b[1;33m:\u001b[0m \u001b[0mint\u001b[0m \u001b[1;32mif\u001b[0m \u001b[0munique\u001b[0m \u001b[0mindex\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mpossibly\u001b[0m \u001b[0mslice\u001b[0m \u001b[1;32mor\u001b[0m \u001b[0mmask\u001b[0m \u001b[1;32mif\u001b[0m \u001b[1;32mnot\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1384\u001b[0m         \"\"\"\n\u001b[1;32m-> 1385\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_engine\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget_loc\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0m_values_from_object\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1386\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1387\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mget_value\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mseries\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkey\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
        "\u001b[1;32mC:\\Users\\mfinemorris\\AppData\\Local\\Enthought\\Canopy\\User\\lib\\site-packages\\pandas\\index.pyd\u001b[0m in \u001b[0;36mpandas.index.IndexEngine.get_loc (pandas\\index.c:3795)\u001b[1;34m()\u001b[0m\n",
        "\u001b[1;32mC:\\Users\\mfinemorris\\AppData\\Local\\Enthought\\Canopy\\User\\lib\\site-packages\\pandas\\index.pyd\u001b[0m in \u001b[0;36mpandas.index.IndexEngine.get_loc (pandas\\index.c:3675)\u001b[1;34m()\u001b[0m\n",
        "\u001b[1;32mC:\\Users\\mfinemorris\\AppData\\Local\\Enthought\\Canopy\\User\\lib\\site-packages\\pandas\\hashtable.pyd\u001b[0m in \u001b[0;36mpandas.hashtable.PyObjectHashTable.get_item (pandas\\hashtable.c:12299)\u001b[1;34m()\u001b[0m\n",
        "\u001b[1;32mC:\\Users\\mfinemorris\\AppData\\Local\\Enthought\\Canopy\\User\\lib\\site-packages\\pandas\\hashtable.pyd\u001b[0m in \u001b[0;36mpandas.hashtable.PyObjectHashTable.get_item (pandas\\hashtable.c:12250)\u001b[1;34m()\u001b[0m\n",
        "\u001b[1;31mKeyError\u001b[0m: '0.95'"
       ]
      }
     ],
     "prompt_number": 85
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "rd_index = data_raw.index\n",
      "p_index = sliding_p_count.index\n",
      "for num, key in enumerate(data_raw[1:]):\n",
      "    peak_data = sliding_p_count[key]\n",
      "    raw_data = data_raw[key]\n",
      "    \n",
      "    fig = plt.figure(num)\n",
      "    fig.subplots_adjust(hspace=0.1)\n",
      "\n",
      "    ax1 = plt.subplot(211)\n",
      "    ax1.plot(rd_index, raw_data)\n",
      "    plt.ylabel('Membrane Potential (mV)')\n",
      "    plt.title(\"sliding peak count, \" + variable + \" = \"+ key)\n",
      "\n",
      "    ax2 = plt.subplot(212, sharex=ax1)\n",
      "    ax2.plot(p_index, peak_data, marker = '.')\n",
      "    plt.xlabel(\"Time (ms)\")\n",
      "    plt.ylabel(\"# Peaks\")\n",
      "    \n",
      "    plot_file = os.path.join(output_directory,\"sliding_peaks-\"+key.replace(\".\",\"_\")+\"-\"+plot_suffix)\n",
      "    print plot_file\n",
      "    fig.savefig(plot_file)\n",
      "plt.show()"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "C:\\Users\\mfinemorris\\repos\\WilsonLab\\NMAnalysis\\sliding_peaks--55-BRSModel-sec1320-eL.png\n",
        "C:\\Users\\mfinemorris\\repos\\WilsonLab\\NMAnalysis\\sliding_peaks--60-BRSModel-sec1320-eL.png"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "C:\\Users\\mfinemorris\\repos\\WilsonLab\\NMAnalysis\\sliding_peaks--65-BRSModel-sec1320-eL.png"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n"
       ]
      }
     ],
     "prompt_number": 86
    },
    {
     "cell_type": "heading",
     "level": 2,
     "metadata": {},
     "source": [
      "Optional Blocks"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "#all time series overlay\n",
      "plt.plot(data_raw, label= data_raw.columns)\n",
      "plt.xlim(xmin = 30000, xmax = 45000)\n",
      "plt.show()"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 30
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "#quick plot all events with specail start and end colors.\n",
      "meas = '0.95' #which setting to graph\n",
      "\n",
      "plt.plot(data_raw.index, data_raw[meas], color = 'k')\n",
      "plt.plot(peaks[meas].index, peaks[meas]['Amplitude'], marker ='^', color = 'g', linestyle = 'None')\n",
      "for index, row in bursts[meas]['Start'].iteritems():\n",
      "    plt.plot(row, peaks[meas]['Amplitude'].loc[row], marker ='^', color = 'm', linestyle = 'None')\n",
      "for index, row in bursts[meas]['End'].iteritems():\n",
      "    plt.plot(row, peaks[meas]['Amplitude'].loc[row], marker ='^', color = 'y', linestyle = 'None')\n",
      "#plt.xlim(xmin = 30000, xmax = 45000)\n",
      "plt.title('%s - %s' %(exp, meas))\n",
      "plt.xlabel('Time (ms)')\n",
      "plt.ylabel('Voltage')\n",
      "plt.show()"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 31
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "#quick plot of events\n",
      "label = meas\n",
      "plt.plot(data_raw.index, data_raw[label])\n",
      "plt.plot(peak_sets_temp_x[label], peak_sets_temp_y[label], marker = \"^\", color=\"y\", linestyle= \"None\")\n",
      "plt.title(label)\n",
      "plt.show()"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 33
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 41
    },
    {
     "cell_type": "heading",
     "level": 1,
     "metadata": {},
     "source": [
      "Save out settings and analysis"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "import NMResources as nmr\n",
      "import operator\n",
      "from pprint import pprint\n",
      "import json\n",
      "output_file = os.path.join(output_directory,\"misc-\"+output_suffix+\".csv\")"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 87
    },
    {
     "cell_type": "heading",
     "level": 2,
     "metadata": {},
     "source": [
      "Save Data"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "#make all dataframes into csv strings\n",
      "#separate them from other elements of dictionary\n",
      "formatted_output = {}\n",
      "for i,ii in output_dict.iteritems():\n",
      "    try:\n",
      "        formatted_output[i]=ii.to_dict()\n",
      "    except:\n",
      "        formatted_output[i]=ii\n",
      "        \n",
      "with open(output_file,'w') as f:\n",
      "    json.dump(formatted_output,f)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 88
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "pat_ind = output_dict['peak_amp_temp'].index\n",
      "output_dict['peak_amp_temp']"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "html": [
        "<div style=\"max-height:1000px;max-width:1500px;overflow:auto;\">\n",
        "<table border=\"1\" class=\"dataframe\">\n",
        "  <thead>\n",
        "    <tr style=\"text-align: right;\">\n",
        "      <th></th>\n",
        "      <th>0.9</th>\n",
        "      <th>0.95</th>\n",
        "      <th>1.0</th>\n",
        "      <th>1.2</th>\n",
        "    </tr>\n",
        "  </thead>\n",
        "  <tbody>\n",
        "    <tr>\n",
        "      <th>count</th>\n",
        "      <td>  0</td>\n",
        "      <td> 887.000000</td>\n",
        "      <td> 2148.000000</td>\n",
        "      <td> 3119.000000</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>mean</th>\n",
        "      <td>NaN</td>\n",
        "      <td>   5.209998</td>\n",
        "      <td>    5.450821</td>\n",
        "      <td>    4.641696</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>std</th>\n",
        "      <td>NaN</td>\n",
        "      <td>   1.709528</td>\n",
        "      <td>    1.107147</td>\n",
        "      <td>    6.659212</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>min</th>\n",
        "      <td>NaN</td>\n",
        "      <td> -44.963484</td>\n",
        "      <td>  -45.411611</td>\n",
        "      <td>  -45.888449</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>25%</th>\n",
        "      <td>NaN</td>\n",
        "      <td>   5.015600</td>\n",
        "      <td>    5.360962</td>\n",
        "      <td>    5.484921</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>50%</th>\n",
        "      <td>NaN</td>\n",
        "      <td>   5.246601</td>\n",
        "      <td>    5.472068</td>\n",
        "      <td>    5.540429</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>75%</th>\n",
        "      <td>NaN</td>\n",
        "      <td>   5.508012</td>\n",
        "      <td>    5.575864</td>\n",
        "      <td>    5.589770</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>max</th>\n",
        "      <td>NaN</td>\n",
        "      <td>   5.946941</td>\n",
        "      <td>    5.896579</td>\n",
        "      <td>    5.802625</td>\n",
        "    </tr>\n",
        "  </tbody>\n",
        "</table>\n",
        "</div>"
       ],
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 130,
       "text": [
        "       0.9        0.95          1.0          1.2\n",
        "count    0  887.000000  2148.000000  3119.000000\n",
        "mean   NaN    5.209998     5.450821     4.641696\n",
        "std    NaN    1.709528     1.107147     6.659212\n",
        "min    NaN  -44.963484   -45.411611   -45.888449\n",
        "25%    NaN    5.015600     5.360962     5.484921\n",
        "50%    NaN    5.246601     5.472068     5.540429\n",
        "75%    NaN    5.508012     5.575864     5.589770\n",
        "max    NaN    5.946941     5.896579     5.802625"
       ]
      }
     ],
     "prompt_number": 130
    },
    {
     "cell_type": "heading",
     "level": 2,
     "metadata": {},
     "source": [
      "Extract Data"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "#Extract Data\n",
      "with open(output_file,'r') as f:\n",
      "    misc_data = json.load(f)\n",
      "print misc_data.keys()\n",
      "\n",
      "temp = {}\n",
      "\n",
      "for k,v in misc_data.iteritems():\n",
      "    try:\n",
      "        temp[k] = pd.DataFrame.from_dict(v)\n",
      "        print k\n",
      "    except:\n",
      "        temp[k] = v\n",
      "        print k, \": \", v\n",
      "        \n",
      "temp['peak_amp_temp'].reindex_axis(pat_ind)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "[u'burst_stat_data', u'peak_amp_temp', u'ibi_avg_std', u'ibi_thresh', u'File_Path', u'rate', u'exp', u'sg_setting']\n",
        "burst_stat_data\n",
        "peak_amp_temp\n",
        "ibi_avg_std\n",
        "ibi_thresh :  200\n",
        "File_Path :  C:\\Users\\mfinemorris\\Desktop\\Parallel Model Code\\Results\\voltage-TBModel-sec300-IP-gL2_5.txt\n",
        "rate :  0.100000033333\n",
        "exp :  TBModel with sec300, IP, gL2_5\n",
        "sg_setting :  301\n"
       ]
      },
      {
       "html": [
        "<div style=\"max-height:1000px;max-width:1500px;overflow:auto;\">\n",
        "<table border=\"1\" class=\"dataframe\">\n",
        "  <thead>\n",
        "    <tr style=\"text-align: right;\">\n",
        "      <th></th>\n",
        "      <th>0.9</th>\n",
        "      <th>0.95</th>\n",
        "      <th>1.0</th>\n",
        "      <th>1.2</th>\n",
        "    </tr>\n",
        "  </thead>\n",
        "  <tbody>\n",
        "    <tr>\n",
        "      <th>count</th>\n",
        "      <td>  0</td>\n",
        "      <td> 887.000000</td>\n",
        "      <td> 2148.000000</td>\n",
        "      <td> 3119.000000</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>mean</th>\n",
        "      <td>NaN</td>\n",
        "      <td>   5.209998</td>\n",
        "      <td>    5.450821</td>\n",
        "      <td>    4.641696</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>std</th>\n",
        "      <td>NaN</td>\n",
        "      <td>   1.709528</td>\n",
        "      <td>    1.107147</td>\n",
        "      <td>    6.659212</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>min</th>\n",
        "      <td>NaN</td>\n",
        "      <td> -44.963484</td>\n",
        "      <td>  -45.411611</td>\n",
        "      <td>  -45.888449</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>25%</th>\n",
        "      <td>NaN</td>\n",
        "      <td>   5.015600</td>\n",
        "      <td>    5.360962</td>\n",
        "      <td>    5.484921</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>50%</th>\n",
        "      <td>NaN</td>\n",
        "      <td>   5.246601</td>\n",
        "      <td>    5.472068</td>\n",
        "      <td>    5.540429</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>75%</th>\n",
        "      <td>NaN</td>\n",
        "      <td>   5.508012</td>\n",
        "      <td>    5.575864</td>\n",
        "      <td>    5.589770</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>max</th>\n",
        "      <td>NaN</td>\n",
        "      <td>   5.946941</td>\n",
        "      <td>    5.896579</td>\n",
        "      <td>    5.802625</td>\n",
        "    </tr>\n",
        "  </tbody>\n",
        "</table>\n",
        "</div>"
       ],
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 183,
       "text": [
        "       0.9        0.95          1.0          1.2\n",
        "count    0  887.000000  2148.000000  3119.000000\n",
        "mean   NaN    5.209998     5.450821     4.641696\n",
        "std    NaN    1.709528     1.107147     6.659212\n",
        "min    NaN  -44.963484   -45.411611   -45.888449\n",
        "25%    NaN    5.015600     5.360962     5.484921\n",
        "50%    NaN    5.246601     5.472068     5.540429\n",
        "75%    NaN    5.508012     5.575864     5.589770\n",
        "max    NaN    5.946941     5.896579     5.802625"
       ]
      }
     ],
     "prompt_number": 183
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "#any key in output_dict that is suffixed with \"_\" should get its own file\n",
      "#what should the output file names look like?\n",
      "\n",
      "#make dir with \n",
      "small_info = {}\n",
      "for key,val in output_dict.items():\n",
      "    #print\n",
      "    if key.endswith('_'):\n",
      "        path = output_dict['File_Path']\n",
      "        basefile = os.path.basename(path)\n",
      "        file_name_parts = basefile.split(\"-\")\n",
      "        new_file_name = \"-\".join([key[:-1]]+file_name_parts[1:])\n",
      "        print key, basefile, new_file_name\n",
      "        #print type(val)\n",
      "        #now write file\n",
      "    else:\n",
      "        small_info[key] = val\n",
      "print\n",
      "print small_info\n",
      "output_dict.keys()"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "{'burst_stat_data':       duration mean  duration std     ibi mean    ibi std\n",
        "0.9             NaN           NaN          NaN        NaN\n",
        "0.95     356.812619      7.056491  8567.724731   6.024775\n",
        "1.0      317.836380      8.984696  2602.449887   8.342934\n",
        "1.2      382.375127     13.851072  1441.743773  13.674764, 'peak_amp_temp':        0.9        0.95          1.0          1.2\n",
        "count    0  887.000000  2148.000000  3119.000000\n",
        "mean   NaN    5.209998     5.450821     4.641696\n",
        "std    NaN    1.709528     1.107147     6.659212\n",
        "min    NaN  -44.963484   -45.411611   -45.888449\n",
        "25%    NaN    5.015600     5.360962     5.484921\n",
        "50%    NaN    5.246601     5.472068     5.540429\n",
        "75%    NaN    5.508012     5.575864     5.589770\n",
        "max    NaN    5.946941     5.896579     5.802625, 'ibi_thresh': 200, 'File_Path': 'C:\\\\Users\\\\mfinemorris\\\\Desktop\\\\Parallel Model Code\\\\Results\\\\voltage-TBModel-sec300-IP-gL2_5.txt', 'rate': 0.1000000333333444, 'exp': 'TBModel with sec300, IP, gL2_5', 'sg_setting': 301}\n"
       ]
      },
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 124,
       "text": [
        "['burst_stat_data',\n",
        " 'peak_amp_temp',\n",
        " 'sg_setting',\n",
        " 'File_Path',\n",
        " 'rate',\n",
        " 'exp',\n",
        " 'ibi_thresh']"
       ]
      }
     ],
     "prompt_number": 124
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "def all_time_series(data_raw, peaks, bursts, exp, output_directory):\n",
      "    '''\n",
      "    create and save all time series. requires that event detection has been performed. \n",
      "    saves out plots of graphs with the same scale, 30 s - 45 s.\n",
      "    '''\n",
      "    \n",
      "    for label, column in data_raw.iteritems():\n",
      "        \n",
      "        plt.figure()\n",
      "        plt.plot(data_raw.index, data_raw[label], color = 'k')\n",
      "        plt.plot(peaks[label].index, peaks[label]['Amplitude'], marker ='^', color = 'g', linestyle = 'None')\n",
      "        for index, row in bursts[label]['Start'].iteritems():\n",
      "            plt.plot(row, peaks[label]['Amplitude'].loc[row], marker ='^', color = 'm', linestyle = 'None')\n",
      "        for index, row in bursts[label]['End'].iteritems():\n",
      "            plt.plot(row, peaks[label]['Amplitude'].loc[row], marker ='^', color = 'y', linestyle = 'None')\n",
      "        plt.xlim(xmin = 30000, xmax = 45000)\n",
      "        plt.title('%s - %s' %(exp, label))\n",
      "        plt.xlabel('Time (ms)')\n",
      "        plt.ylabel('Voltage')\n",
      "        plt.savefig(r'%s/Time Series - %s.pdf'%(output_directory, label))\n",
      "        plt.close()\n",
      "\n",
      "all_time_series(data_raw, peaks, bursts, exp, output_directory)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 33
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "for i in plt.get_fignums():\n",
      "    plt.figure(i)\n",
      "    plt.show()\n",
      "    plt.savefig('figure%d.png' % i)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 35
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [],
     "language": "python",
     "metadata": {},
     "outputs": []
    }
   ],
   "metadata": {}
  }
 ]
}