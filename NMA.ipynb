{
 "metadata": {
  "name": "",
  "signature": "sha256:6c6092f1acbde715d665f0e9e92f6d8d3148c4c4b83b24b571f5e9297f3077c1"
 },
 "nbformat": 3,
 "nbformat_minor": 0,
 "worksheets": [
  {
   "cells": [
    {
     "cell_type": "heading",
     "level": 1,
     "metadata": {},
     "source": [
      "Neuron Modeling Analysis"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "import numpy as np\n",
      "import scipy\n",
      "from scipy import spatial, signal, fft, arange\n",
      "import pandas as pd\n",
      "import matplotlib.pyplot as plt\n",
      "from pandas import Series, DataFrame\n",
      "import time as t\n",
      "from PIL import Image\n",
      "import sys\n",
      "import os, errno\n",
      "import matplotlib.patches as patches\n",
      "from pandas.tools.plotting import autocorrelation_plot\n",
      "#from pyeeg import * \n",
      "from numpy import NaN, Inf, arange, isscalar, asarray, array\n",
      "from matplotlib.backends.backend_pdf import PdfPages\n",
      "\n",
      "def mkdir_p(path):\n",
      "    '''\n",
      "    This function creates a folder at the end of the specified path, unless the folder already exsists. \n",
      "    '''\n",
      "    try:\n",
      "        os.makedirs(path)\n",
      "    except OSError as exc: # Python >2.5\n",
      "        if exc.errno == errno.EEXIST and os.path.isdir(path):\n",
      "            pass #do nothing if the error occurs because the path already exists\n",
      "        else: raise #re-raises the error\n",
      "    \n",
      "def delta_tuner(dataframe, epsilon, rate): #choose which data to use to tune. can be either selected list or full ist. AD reccoments full list.\n",
      "    '''\n",
      "    this function takes a dataframe of time series data and runs peak detection iteritvely. \n",
      "    since peak detection always has the the range of delta values of 0 to the max of stack,\n",
      "    epsiolon is used to be the number of divisions of that range to test. 1 being the minimum for epsilon, which is the exact middle of the range.\n",
      "    the function will return a results table (average # of events) and (# ROIs with events>1) on their own axis.\n",
      "    the graph will be click able, as to obtain the delta value that generated that point.\n",
      "    data results are not saved.\n",
      "    '''\n",
      "    \n",
      "    range_array = np.linspace(0, max(dataframe.max())/2, num = epsilon) #create the array of which delta values to test. the range is from zero (although zero is not used) to half of the max value from the entire data frame. epsilon is used to determine the number of slices to make\n",
      "    \n",
      "    results_average = Series(index = range_array) #the empty series to store results\n",
      "    results_num = Series (index = range_array) #an empty series to store results\n",
      "    #results_perc = Series (index = range_array)\n",
      "    \n",
      "    for delta in range_array[1:]: #for each delta value in the array\n",
      "        \n",
      "        peak_amp_temp, peak_sets_temp_x, peak_sets_temp_y = event_detection(dataframe,delta, rate) #perform event detection with the delta\n",
      "\n",
      "        event_counts = peak_amp_temp.loc['count'] #count the number of events, which is a row in the peak_amp_temp array\n",
      "        average_num_events = event_counts.mean() #average the counts, to obtain (average # events/roi)\n",
      "        num_roi = event_counts[event_counts>=1].count() #count the number of ROIs with more than one event\n",
      "        \n",
      "        #perc_roi = num_roi/len(data_smooth.columns)\n",
      "\n",
      "        results_average[delta] = average_num_events \n",
      "        results_num[delta] = num_roi\n",
      "        #results_perc[delta]= perc_roi\n",
      "    return results_average, results_num\n",
      "\n",
      "def savitzky_golay(y, window_size, order, deriv=0, rate=1):\n",
      "    r\"\"\"Smooth (and optionally differentiate) data with a Savitzky-Golay filter.\n",
      "    The Savitzky-Golay filter removes high frequency noise from data.\n",
      "    It has the advantage of preserving the original shape and\n",
      "    features of the signal better than other types of filtering\n",
      "    approaches, such as moving averages techniques.\n",
      "    Parameters\n",
      "    ----------\n",
      "    y : array_like, shape (N,)\n",
      "        the values of the time history of the signal.\n",
      "    window_size : int\n",
      "        the length of the window. Must be an odd integer number.\n",
      "    order : int\n",
      "        the order of the polynomial used in the filtering.\n",
      "        Must be less then `window_size` - 1.\n",
      "    deriv: int\n",
      "        the order of the derivative to compute (default = 0 means only smoothing)\n",
      "    Returns\n",
      "    -------\n",
      "    ys : ndarray, shape (N)\n",
      "        the smoothed signal (or it's n-th derivative).\n",
      "    Notes\n",
      "    -----\n",
      "    The Savitzky-Golay is a type of low-pass filter, particularly\n",
      "    suited for smoothing noisy data. The main idea behind this\n",
      "    approach is to make for each point a least-square fit with a\n",
      "    polynomial of high order over a odd-sized window centered at\n",
      "    the point.\n",
      "    Examples\n",
      "    --------\n",
      "    t = np.linspace(-4, 4, 500)\n",
      "    y = np.exp( -t**2 ) + np.random.normal(0, 0.05, t.shape)\n",
      "    ysg = savitzky_golay(y, window_size=31, order=4)\n",
      "    import matplotlib.pyplot as plt\n",
      "    plt.plot(t, y, label='Noisy signal')\n",
      "    plt.plot(t, np.exp(-t**2), 'k', lw=1.5, label='Original signal')\n",
      "    plt.plot(t, ysg, 'r', label='Filtered signal')\n",
      "    plt.legend()\n",
      "    plt.show()\n",
      "    References\n",
      "    ----------\n",
      "    .. [1] A. Savitzky, M. J. E. Golay, Smoothing and Differentiation of\n",
      "       Data by Simplified Least Squares Procedures. Analytical\n",
      "       Chemistry, 1964, 36 (8), pp 1627-1639.\n",
      "    .. [2] Numerical Recipes 3rd Edition: The Art of Scientific Computing\n",
      "       W.H. Press, S.A. Teukolsky, W.T. Vetterling, B.P. Flannery\n",
      "       Cambridge University Press ISBN-13: 9780521880688\n",
      "    \"\"\"\n",
      "    import numpy as np\n",
      "    from math import factorial\n",
      "\n",
      "    try:\n",
      "        window_size = np.abs(np.int(window_size))\n",
      "        order = np.abs(np.int(order))\n",
      "    except ValueError, msg:\n",
      "        raise ValueError(\"window_size and order have to be of type int\")\n",
      "    if window_size % 2 != 1 or window_size < 1:\n",
      "        raise TypeError(\"window_size size must be a positive odd number\")\n",
      "    if window_size < order + 2:\n",
      "        raise TypeError(\"window_size is too small for the polynomials order\")\n",
      "    order_range = range(order+1)\n",
      "    half_window = (window_size -1) // 2\n",
      "    # precompute coefficients\n",
      "    b = np.mat([[k**i for i in order_range] for k in range(-half_window, half_window+1)])\n",
      "    m = np.linalg.pinv(b).A[deriv] * rate**deriv * factorial(deriv)\n",
      "    # pad the signal at the extremes with\n",
      "    # values taken from the signal itself\n",
      "    firstvals = y[0] - np.abs( y[1:half_window+1][::-1] - y[0] )\n",
      "    lastvals = y[-1] + np.abs(y[-half_window-1:-1][::-1] - y[-1])\n",
      "    y = np.concatenate((firstvals, y, lastvals))\n",
      "    return np.convolve( m[::-1], y, mode='valid')\n",
      "\n",
      "def peakdet(v, delta, x = None):\n",
      "    \"\"\"\n",
      "    Converted from MATLAB script at http://billauer.co.il/peakdet.html\n",
      "    \n",
      "    Returns two arrays\n",
      "    \n",
      "    function [maxtab, mintab]=peakdet(v, delta, x)\n",
      "    %PEAKDET Detect peaks in a vector\n",
      "    %        [MAXTAB, MINTAB] = PEAKDET(V, DELTA) finds the local\n",
      "    %        maxima and minima (\"peaks\") in the vector V.\n",
      "    %        MAXTAB and MINTAB consists of two columns. Column 1\n",
      "    %        contains indices in V, and column 2 the found values.\n",
      "    %      \n",
      "    %        With [MAXTAB, MINTAB] = PEAKDET(V, DELTA, X) the indices\n",
      "    %        in MAXTAB and MINTAB are replaced with the corresponding\n",
      "    %        X-values.\n",
      "    %\n",
      "    %        A point is considered a maximum peak if it has the maximal\n",
      "    %        value, and was preceded (to the left) by a value lower by\n",
      "    %        DELTA.\n",
      "    \n",
      "    % Eli Billauer, 3.4.05 (Explicitly not copyrighted).\n",
      "    % This function is released to the public domain; Any use is allowed.\n",
      "    \n",
      "    \"\"\"\n",
      "    maxtab = []\n",
      "    #mintab = []\n",
      "       \n",
      "    if x is None:\n",
      "        x = arange(len(v))\n",
      "    \n",
      "    v = asarray(v)\n",
      "    \n",
      "    if len(v) != len(x):\n",
      "        sys.exit('Input vectors v and x must have same length')\n",
      "    \n",
      "    if not isscalar(delta):\n",
      "        sys.exit('Input argument delta must be a scalar')\n",
      "    \n",
      "    if delta <= 0:\n",
      "        sys.exit('Input argument delta must be positive')\n",
      "    \n",
      "    mn, mx = Inf, -Inf\n",
      "    mnpos, mxpos = NaN, NaN\n",
      "    \n",
      "    lookformax = True\n",
      "    \n",
      "    for i in arange(len(v)):\n",
      "        this = v[i]\n",
      "        if this > mx:\n",
      "            mx = this\n",
      "            mxpos = x[i]\n",
      "        if this < mn:\n",
      "            mn = this\n",
      "            mnpos = x[i]\n",
      "        \n",
      "        if lookformax:\n",
      "            if this < mx-delta:\n",
      "                maxtab.append((mxpos, mx))\n",
      "                mn = this\n",
      "                mnpos = x[i]\n",
      "                lookformax = False\n",
      "        else:\n",
      "            if this > mn+delta:\n",
      "                #mintab.append((mnpos, mn))\n",
      "                mx = this\n",
      "                mxpos = x[i]\n",
      "                lookformax = True\n",
      " \n",
      "    return array(maxtab)#, array(mintab)\n",
      "\n",
      "\n",
      "def event_detection(data, delta, rate):\n",
      "    '''\n",
      "    do peak detect on a dataframe. takes a delta value and the rate.\n",
      "    A point is considered a maximum peak if it has the maximal value, and was preceded (to the left) by a value lower by DELTA.\n",
      "    '''\n",
      "    \n",
      "    #results storage\n",
      "    peak_amp_temp = DataFrame()\n",
      "    rr_int_temp = DataFrame()\n",
      "    peak_sets_temp_x = {} #time\n",
      "    peak_sets_temp_y = {} #amplitude\n",
      "\n",
      "    for label, column in data.iteritems(): #for each column in the data frame\n",
      "        start_time = t.clock()\n",
      "        time = column.index.tolist() #time array\n",
      "        col = column.tolist() #amplitude array\n",
      "\n",
      "        #peakdet\n",
      "        maxtab = peakdet(col, delta,None)\n",
      "\n",
      "        maxtab = np.array(maxtab)\n",
      "\n",
      "        if maxtab.size == 0: #how to handle empty np array, which occurs if no events are detected\n",
      "            maxptime = []\n",
      "            maxpeaks = []\n",
      "        \n",
      "        else:\n",
      "            maxptime = maxtab[:,0] #all of the rows and only the first column are time\n",
      "            maxpeaks = maxtab[:,1] #all of the rows and only the second column are amp.\n",
      "\n",
      "        maxptime_true = (np.multiply(maxptime,rate) + time[0]) #get the real time for each peak, since the peak is given in index not time\n",
      "        peak_sets_temp_x[label] = maxptime_true #store array of event time in the dictionary with the ROI name as the key\n",
      "\n",
      "        peak_sets_temp_y[label] = np.array(maxpeaks) #store array of events in the dictionary with the ROI name as the key\n",
      "        #RR = rrinterval(maxptime_true)\n",
      "        peak_amp_temp[label] = Series(data = maxpeaks, index=maxptime_true).describe() #store summary data series in the summary dataframe\n",
      "        #rr_int_temp[label] = Series(data = RR, index=maxptime_true[:-1]).describe()\n",
      "        end_time = t.clock()\n",
      "        print label, 'took', (end_time - start_time), 'seconds to run'\n",
      "    return peak_amp_temp, peak_sets_temp_x, peak_sets_temp_y\n",
      "\n",
      "def line_plots(data_orignal, data_smooth, events_x, events_y, peak_sets_temp_x, peak_sets_temp_y, event_summary,folder):\n",
      "    '''\n",
      "    creates the plots with two lines: original data and smoothed data. it also overlays the events from LCpro and RAIN.\n",
      "    '''\n",
      "    lcpro_events_select_list = event_summary[event_summary['LCpro, select'] >= 1].index.tolist() #list of only roi's found by RAIN\n",
      "    \n",
      "    for label, column in data_orignal.iteritems():\n",
      "        \n",
      "        plt.figure()\n",
      "        plt.xlabel('Time (s)')\n",
      "        plt.ylabel('Intensity')\n",
      "        plt.title(label)\n",
      "        plt.ylim(ymin = min(data_orignal.min()), ymax = max(data_orignal.max()))\n",
      "        plt.xlim(xmin = data_orignal.index[0], xmax = data_orignal.index[-1])\n",
      "        \n",
      "        plt.plot(data_orignal.index, data_orignal[label], label = 'original', color = 'r')\n",
      "        plt.plot(data_orignal.index, data_smooth[label], label = 'smooth', color = 'b')\n",
      "        if label in data_orignal.columns:     \n",
      "            plt.plot(events_x[label], events_y[label], marker = \"^\", color=\"r\", linestyle= \"None\")\n",
      "        if label in lcpro_events_select_list:\n",
      "            plt.plot(events_x[label], events_y[label], marker = \"^\", color=\"g\", linestyle= \"None\")\n",
      "        if label in peak_sets_temp_x.keys():\n",
      "            plt.plot(peak_sets_temp_x[label], peak_sets_temp_y[label], marker = \"^\", color=\"y\", linestyle= \"None\")\n",
      "        plt.savefig(r'%s/plots/%s.pdf' %(folder,label))\n",
      "        plt.close()\n",
      "\n",
      "def rrinterval(maxptime): \n",
      "    \"\"\"\n",
      "    find time from r peak to r peak, called the R-R interval. Input array must be a list of numbers (float).\n",
      "    \"\"\"\n",
      "    \n",
      "    rrint = [] #empty array for ttot to go into\n",
      "    \n",
      "    for time in maxptime[1:]: #for each r peak, starting with the second one\n",
      "        s2time = maxptime.index(time) \n",
      "        s2 = maxptime[s2time-1]\n",
      "        meas = time - s2 #measure the interval by subtracting\n",
      "        rrint.append(meas) #append the measurement to the ttotal array\n",
      "    return rrint #return array\n",
      "\n",
      "print \"Notebook initalized\"    "
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "Notebook initalized\n"
       ]
      }
     ],
     "prompt_number": 14
    },
    {
     "cell_type": "heading",
     "level": 1,
     "metadata": {},
     "source": [
      "Define Folders and File Paths. Import Data and Plot Data."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "results_folder = os.path.join(os.getcwd(), 'NMResults')\n",
      "mkdir_p(results_folder) #if path alread exists, nothing will happen and no message will be displayed\n",
      "\n",
      "data_file = 'voltage-TBModel-sec300-IP-gL2_5.txt'\n",
      "File_Path = os.path.join(results_folder, data_file)\n",
      "if not os.path.isfile(File_Path):\n",
      "    print \"Cannot find file\",data_file\n",
      "else:\n",
      "    file_info = data_file.partition('.')[0].split(\"-\")\n",
      "\n",
      "variable = file_info[3]\n",
      "file_info"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 61,
       "text": [
        "['voltage', 'TBModel', 'sec300', 'IP', 'gL2_5']"
       ]
      }
     ],
     "prompt_number": 61
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "data_raw = pd.read_csv(File_Path, index_col= 0)\n",
      "\n",
      "output_dict = {} # reset output dict each time I load a new data file\n",
      "plot_dict={}\n",
      "\n",
      "output_dict['File_Path'] = File_Path"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 23
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "plot_ext = \".png\"\n",
      "data_ext = \".txt\""
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 32
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "output_directory = os.path.join(os.getcwd(), 'NMAnalysis')\n",
      "exp_info = \"-\".join(file_info[1:])\n",
      "output_suffix = exp_info + data_ext\n",
      "plot_suffix = exp_info + plot_ext\n",
      "#output_directory = \"/Users/mfinemorris/Desktop/Neuron Modeling\"\n",
      "mkdir_p(output_directory)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 33
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "data_raw.columns"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 6,
       "text": [
        "Index([u'0.9', u'0.95', u'1.0', u'1.2'], dtype='object')"
       ]
      }
     ],
     "prompt_number": 6
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "meas = '2.8'\n",
      "plt.plot(data_raw.index, data_raw[meas])\n",
      "plt.show()"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "#plot all raw data time series\n",
      "for label, column in data_raw.iteritems():\n",
      "    \n",
      "    plt.plot(data_raw.index, column)\n",
      "    plt.title(label)\n",
      "    plt.show()"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "heading",
     "level": 1,
     "metadata": {},
     "source": [
      "Process Data"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "#Sav golay the array with all the same setting\n",
      "sg_setting = 301\n",
      "data_smooth = DataFrame(index = data_raw.index)\n",
      "for label, column in data_raw.iteritems():\n",
      "    temp_list = column.tolist()\n",
      "    temp_list = savitzky_golay(temp_list, sg_setting, 4)\n",
      "    data_smooth[label] = temp_list\n",
      "output_dict['sg_setting'] = sg_setting\n",
      "#output_dict['data_smooth_'] = data_smooth"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 26
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "#output data_smooth\n",
      "save_file = os.path.join(output_directory,'data_smooth-'+output_suffix)\n",
      "print save_file\n",
      "data_smooth.to_csv(save_file)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "C:\\Users\\mfinemorris\\repos\\WilsonLab\\NMAnalysis\\data_smooth-TBModel-sec300-IP-gL2_5.txt\n"
       ]
      }
     ],
     "prompt_number": 44
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "def plot_smooth():\n",
      "    #plot smoothes series\n",
      "    for label, column in data_smooth.iteritems():\n",
      "        plt.plot(data_smooth.index, column)\n",
      "        plt.title(label)\n",
      "#        plot_file = os.path.join(output_directory,\"data_smooth-\"+label.replace(\".\",\"_\")+'-'+exp_info)\n",
      "#        print plot_file\n",
      "#        plt.savefig(plot_file)\n",
      "        #plt.show()"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "C:\\Users\\mfinemorris\\repos\\WilsonLab\\NMAnalysis\\data_smooth-0_9-TBModel-sec300-IP-gL2_5.png\n",
        "C:\\Users\\mfinemorris\\repos\\WilsonLab\\NMAnalysis\\data_smooth-0_95-TBModel-sec300-IP-gL2_5.png"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "C:\\Users\\mfinemorris\\repos\\WilsonLab\\NMAnalysis\\data_smooth-1_0-TBModel-sec300-IP-gL2_5.png"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "C:\\Users\\mfinemorris\\repos\\WilsonLab\\NMAnalysis\\data_smooth-1_2-TBModel-sec300-IP-gL2_5.png"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n"
       ]
      }
     ],
     "prompt_number": 40
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "pdf_file = os.path.join(output_directory,\"data_smooth\"+\"-\"+plot_suffix.replace(plot_ext,\"\"))\n",
      "pp = PdfPages(pdf_file+'.pdf')\n",
      "\n",
      "def plot_smooth():\n",
      "    #plot smoothes series\n",
      "    for label, column in data_smooth.iteritems():\n",
      "        plt.plot(data_smooth.index, column)\n",
      "        plt.title(label)\n",
      "#        plot_file = os.path.join(output_directory,\"data_smooth-\"+label.replace(\".\",\"_\")+'-'+exp_info)\n",
      "#        print plot_file\n",
      "#        plt.savefig(plot_file)\n",
      "        #plt.show()\n",
      "\n",
      "rd_index = data_raw.index\n",
      "p_index = sliding_p_count.index\n",
      "for num, key in enumerate(data_raw[1:]):\n",
      "    peak_data = sliding_p_count[key]\n",
      "    raw_data = data_raw[key]\n",
      "    \n",
      "    plt.figure(num)\n",
      "    plt.subplot(211)\n",
      "    plt.plot(rd_index, raw_data)\n",
      "    plt.subplot(212)\n",
      "    plt.plot(p_index, peak_data, marker = '.')\n",
      "    plt.subplots_adjust(hspace=0.1)\n",
      "    pp.savefig()\n",
      "\n",
      "pp.close()\n",
      "plt.show()"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "rate = data_raw.index[3] - data_raw.index[2]\n",
      "rate\n",
      "output_dict['rate'] = rate"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 41
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "exp = (file_info[1]+\" with \"+\", \".join(file_info[2:])).replace(\"_\",\".\")\n",
      "output_dict['exp'] = exp\n",
      "exp"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 72,
       "text": [
        "'TBModel with sec300, IP, gL2.5'"
       ]
      }
     ],
     "prompt_number": 72
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "#event detection on all time series\n",
      "delta = 1\n",
      "peak_amp_temp, peak_sets_temp_x, peak_sets_temp_y = event_detection(data_raw, delta, rate)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "0.9 took 4.07486454362 seconds to run\n",
        "0.95"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " took 4.27271456053 seconds to run\n",
        "1.0"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " took 4.0735640213 seconds to run\n",
        "1.2"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " took 4.16264611232 seconds to run\n"
       ]
      }
     ],
     "prompt_number": 43
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "#save peak data for later operations in notebook\n",
      "peaks = {} \n",
      "\n",
      "#save peak data for later output\n",
      "peak_y = peak_sets_temp_y\n",
      "peak_x = peak_sets_temp_x\n",
      "temp = []\n",
      "\n",
      "#index/cols for the peak array that will be saved to file\n",
      "cols = pd.MultiIndex(levels=[[u'0.9', u'0.95', u'1.0', u'1.2'], [u'rr', u'x', u'y']],\n",
      "           labels=[[0, 0, 0, 1, 1, 1, 2, 2, 2, 3, 3, 3], [1, 2, 0, 1, 2, 0, 1, 2, 0, 1, 2, 0]],\n",
      "           names=[u'variable', u'peak data'])\n",
      "\n",
      "max_peaks = max([len(peak_x[key]) for key in peak_x])\n",
      "\n",
      "for k in peak_x:\n",
      "    start_time = t.clock()\n",
      "\n",
      "    #### Collect peak data for later notebook operations\n",
      "    xlist = peak_x[k].tolist()\n",
      "    #get RR interval\n",
      "    RR = rrinterval(xlist)\n",
      "    RR.append(NaN)\n",
      "    peaks[k] = DataFrame({'Amplitude':peak_y[k].tolist(),'Interval':RR}, index = xlist)\n",
      "\n",
      "    #### Collect peak data for saving\n",
      "    temp.append(peak_x[k])\n",
      "    temp.append(peak_y[k])\n",
      "    temp.append(RR[:-1])\n",
      "    \n",
      "    end_time = t.clock()\n",
      "    print k, \"finished in\", np.round(end_time - start_time, 3)\n",
      "    \n",
      "peak_x_y = pd.DataFrame(data=temp, index=cols, columns=range(0,max_peaks)).T.to_sparse()\n",
      "\n",
      "output_dict['peak_amp_temp'] = peak_amp_temp\n",
      "#output_dict['peaks_'] = peak_x_y"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "0.9 finished in 0.001\n",
        "0.95 finished in 0.007\n",
        "1.0 finished in 0.037\n",
        "1.2"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " finished in 0.076\n"
       ]
      }
     ],
     "prompt_number": 45
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "save_file = os.path.join(output_directory,'peaks-'+output_suffix)\n",
      "print save_file\n",
      "# IDK why this works and peak_x_y.to_csv() doesn't, but you can't argue with results...\n",
      "peak_dict = peak_x_y.to_dict()\n",
      "pd.DataFrame().from_dict(peak_dict).to_csv(save_file)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "C:\\Users\\mfinemorris\\repos\\WilsonLab\\NMAnalysis\\peaks-TBModel-sec300-IP-gL2_5.txt\n"
       ]
      }
     ],
     "prompt_number": 46
    },
    {
     "cell_type": "heading",
     "level": 4,
     "metadata": {},
     "source": [
      "peak to peak measurments, includes ibi"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "#how many peaks occur in each trace?\n",
      "for key, value in peak_sets_temp_x.iteritems():\n",
      "    v = value.tolist()\n",
      "    print key, '=', len(v)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "0.9 = 0\n",
        "0.95 = 887\n",
        "1.0 = 2148\n",
        "1.2 = 3119\n"
       ]
      }
     ],
     "prompt_number": 47
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "#all events detected\n",
      "peaks = {}\n",
      "for key, value in peak_sets_temp_x.iteritems():\n",
      "    start_time = t.clock()\n",
      "    peak_x = value.tolist()\n",
      "    peak_y = peak_sets_temp_y[key].tolist()\n",
      "    \n",
      "    RR = rrinterval(peak_x)\n",
      "    RR.append(NaN)\n",
      "    #make Dataframe with index as peak_x (time of peak) and store amplitude of peak(peak_y) and RR-interval\n",
      "    results_peaks = DataFrame({'Amplitude':peak_y,'Interval':RR}, index = peak_x)  \n",
      "    peaks[key] = results_peaks\n",
      "    end_time = t.clock()\n",
      "    print key, \"finished in\", np.round(end_time - start_time, 3)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "0.9 finished in 0.001\n",
        "0.95 finished in 0.007\n",
        "1.0 finished in 0.037\n",
        "1.2"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " finished in 0.074\n"
       ]
      }
     ],
     "prompt_number": 48
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "#interburst interval detection\n",
      "ibi_thresh = 200 #in ms #!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!\n",
      "ibi_average = Series(index = data_raw.columns)\n",
      "ibi_std = Series(index = data_raw.columns)\n",
      "for key, value in peaks.iteritems():\n",
      "    ibi = value[value['Interval']>ibi_thresh].Interval.mean()\n",
      "    ibi_average[key] = ibi\n",
      "    \n",
      "    std = value[value['Interval']>ibi_thresh].Interval.std()\n",
      "    ibi_std[key] = std\n",
      "    \n",
      "ibi_data = pd.concat({'ibi_average':ibi_average,'ibi_std':ibi_std}, axis=1)\n",
      "\n",
      "output_dict['ibi_thresh'] = ibi_thresh\n",
      "#output_dict['ibi_average'] = ibi_average\n",
      "#output_dict['ibi_std'] = ibi_std\n",
      "\n",
      "output_dict['ibi_avg_std']=ibi_data\n",
      "'''\n",
      "save_file = os.path.join(output_directory,'ibi-'+output_suffix)\n",
      "df = pd.DataFrame().from_dict(ibi_data.to_dict())\n",
      "df.to_csv(save_file)\n",
      "'''\n",
      "print ibi_thresh\n",
      "ibi_data"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "200\n"
       ]
      },
      {
       "html": [
        "<div style=\"max-height:1000px;max-width:1500px;overflow:auto;\">\n",
        "<table border=\"1\" class=\"dataframe\">\n",
        "  <thead>\n",
        "    <tr style=\"text-align: right;\">\n",
        "      <th></th>\n",
        "      <th>ibi_average</th>\n",
        "      <th>ibi_std</th>\n",
        "    </tr>\n",
        "  </thead>\n",
        "  <tbody>\n",
        "    <tr>\n",
        "      <th>0.9</th>\n",
        "      <td>         NaN</td>\n",
        "      <td>       NaN</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>0.95</th>\n",
        "      <td> 8567.724731</td>\n",
        "      <td>  6.024775</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>1.0</th>\n",
        "      <td> 2602.449887</td>\n",
        "      <td>  8.342934</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>1.2</th>\n",
        "      <td> 1441.743773</td>\n",
        "      <td> 13.674764</td>\n",
        "    </tr>\n",
        "  </tbody>\n",
        "</table>\n",
        "</div>"
       ],
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 49,
       "text": [
        "      ibi_average    ibi_std\n",
        "0.9           NaN        NaN\n",
        "0.95  8567.724731   6.024775\n",
        "1.0   2602.449887   8.342934\n",
        "1.2   1441.743773  13.674764"
       ]
      }
     ],
     "prompt_number": 49
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "#ibi summary graph\n",
      "plt.errorbar(ibi_average.index, ibi_average, ibi_std, marker = '^', color = 'k')\n",
      "#plt.xlim(xmin = 0)\n",
      "plt.xlabel('%s' %(exp))\n",
      "plt.ylabel('Interburst Interval (ms)')\n",
      "plt.title('Interburst interval when %s is changed' %exp)\n",
      "plot_dict['ibi_summary'] = plt.gca()\n",
      "plt.show()"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 50
    },
    {
     "cell_type": "heading",
     "level": 4,
     "metadata": {},
     "source": [
      "burst duration"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "bursts = {}\n",
      "burst_arr = []\n",
      "duration = Series(index = data_raw.columns)\n",
      "duration_std = Series(index = data_raw.columns)\n",
      "burst_ibi = Series(index = data_raw.columns)\n",
      "burst_ibi_std = Series(index = data_raw.columns)\n",
      "\n",
      "for key, value in peaks.iteritems():\n",
      "    b_start = []\n",
      "    b_end = []\n",
      "    b_ibi = []\n",
      "    try:\n",
      "        b_start.append(value.index[0])\n",
      "    except IndexError as e:\n",
      "        continue\n",
      "        \n",
      "    b_flag = True\n",
      "\n",
      "    for index, row in value['Interval'].iteritems():\n",
      "        if b_flag == False:\n",
      "            b_start.append(index)\n",
      "            b_flag = True\n",
      "\n",
      "        if b_flag == True:\n",
      "            if row>ibi_thresh:\n",
      "                b_end.append(index)\n",
      "                b_ibi.append(row)\n",
      "                b_flag = False\n",
      "                \n",
      "    if len(b_start) == len(b_end) +1:\n",
      "        del b_start[-1]\n",
      "        \n",
      "    #store info about bursts\n",
      "    Burst = DataFrame(data = {'Start':b_start})\n",
      "    Burst['End'] = b_end\n",
      "    Burst['Duration'] = Burst['End'] - Burst['Start']\n",
      "    Burst['Burst Interval'] = b_ibi\n",
      "    bursts[key] = Burst\n",
      "    \n",
      "    burst_arr.append(b_start)\n",
      "    burst_arr.append(b_end)\n",
      "    burst_arr.append(Burst['Duration'].values.tolist())\n",
      "    burst_arr.append(b_ibi)\n",
      "\n",
      "    \n",
      "    #information derived from burst indo\n",
      "    duration[key] = Burst['Duration'].mean()\n",
      "    duration_std[key] = Burst['Duration'].std()\n",
      "    burst_ibi[key] =  Burst['Burst Interval'].mean()\n",
      "    burst_ibi_std[key] = Burst['Burst Interval'].std()\n",
      "    \n",
      "\n",
      "#store the burst duration- and ibi- mean and std together in prep for final output\n",
      "burst_misc_data = pd.concat([duration, duration_std, burst_ibi, burst_ibi_std],keys=['duration mean','duration std','ibi mean', 'ibi std'], axis=1)#DataFrame(data =,index = data_raw.columns, )\n",
      "#output_dict['bursts_']=bursts\n",
      "output_dict['burst_stat_data'] = burst_misc_data\n",
      "\n",
      "#burst_misc_data"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 51
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "#save bursts\n",
      "save_file = os.path.join(output_directory,'bursts-'+output_suffix)\n",
      "print save_file\n",
      "\n",
      "# IDK why this works when .to_csv doesn't, but you can't argue with results...\n",
      "burst_ind = pd.MultiIndex.from_product([bursts.keys(), [u'start', u'end', u'duration', u'burst interval']], names=['variable','burst data'])\n",
      "burst_df = pd.DataFrame(data=burst_arr, index=burst_ind).T.to_sparse()\n",
      "burst_dict = burst_df.to_dict()\n",
      "pd.DataFrame().from_dict(burst_dict).to_csv(save_file)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "C:\\Users\\mfinemorris\\repos\\WilsonLab\\NMAnalysis\\bursts-TBModel-sec300-IP-gL2_5.txt\n"
       ]
      }
     ],
     "prompt_number": 52
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "file_info"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 57,
       "text": [
        "['voltage', 'TBModel', 'sec300', 'IP', 'gL2_5']"
       ]
      }
     ],
     "prompt_number": 57
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "#burst duration summary plot\n",
      "plt.errorbar(duration.index, duration, duration_std, marker = '^')\n",
      "plt.xlabel('%s' %(variable))\n",
      "plt.ylabel('Burst Duration (ms)')\n",
      "plt.title('Burst duration when %s is changed' %(variable))\n",
      "plot_file = os.path.join(output_directory,\"burst_dur_summary-\"+plot_suffix)\n",
      "print plot_file\n",
      "plt.savefig(plot_file)\n",
      "plt.show()"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "C:\\Users\\mfinemorris\\repos\\WilsonLab\\NMAnalysis\\burst_dur_summary-TBModel-sec300-IP-gL2_5.png\n"
       ]
      }
     ],
     "prompt_number": 73
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "#raster plot\n",
      "for key, value in peak_sets_temp_x.iteritems():\n",
      "    key = float(key)\n",
      "    temp_y = []\n",
      "    for n in value:\n",
      "        temp_y.append(key)\n",
      "    plt.plot(value, temp_y, marker = '.', color = 'k', linestyle = 'None', markersize = 2)\n",
      "plt.xlabel('Time (ms)')\n",
      "plt.ylabel('%s' %variable)\n",
      "y_min = float(peak_sets_temp_x.keys()[0])\n",
      "y_max = float(peak_sets_temp_x.keys()[-1])\n",
      "y_diff = (y_max-y_min)/5\n",
      "plt.ylim(ymin=y_min*(1-y_diff), ymax=y_max*(1+y_diff))\n",
      "#plt.xlim(xmin = 30000, xmax = 45000)\n",
      "plt.title('Raster plot: %s'%exp)\n",
      "plot_file = os.path.join(output_directory,\"raster-\"+plot_suffix)\n",
      "print plot_file\n",
      "plt.savefig(plot_file)\n",
      "plt.show()"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "C:\\Users\\mfinemorris\\repos\\WilsonLab\\NMAnalysis\\raster-TBModel-sec300-IP-gL2_5.png\n"
       ]
      }
     ],
     "prompt_number": 76
    },
    {
     "cell_type": "heading",
     "level": 2,
     "metadata": {},
     "source": [
      "Freq plots"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "import math"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 77
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "key = '1.0' #must be a string "
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 78
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "rris = {}\n",
      "for key in peaks:\n",
      "    rri = peaks[key]['Interval'].tolist()\n",
      "    try:\n",
      "        del rri[-1] #the last value is NaN, so we delete it.\n",
      "    except IndexError:\n",
      "        continue\n",
      "\n",
      "    rri_new = []\n",
      "    for i in rri:\n",
      "        bpm = 60000/i\n",
      "        rri_new.append(bpm)\n",
      "    time_int = peaks[key].index.tolist()\n",
      "    del time_int[-1] #must be the same length as rri\n",
      "\n",
      "    plt.ylabel('Event Rate (events/min.)')\n",
      "    plt.xlabel('Time (s)')\n",
      "    plt.title('Event Freqency-Peak detection')\n",
      "    plt.plot(time_int, rri_new)\n",
      "    plt.show()\n",
      "    ser = pd.Series(data=rri_new, index=time_int)\n",
      "    rris[key] = ser\n",
      "    \n",
      "#output_dict['rris_'] = rris"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 81
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "save_file = os.path.join(output_directory,'rris-'+output_suffix)\n",
      "print save_file\n",
      "pd.DataFrame().from_dict(rris).to_csv(save_file)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "C:\\Users\\mfinemorris\\repos\\WilsonLab\\NMAnalysis\\rris-TBModel-sec300-IP-gL2_5.txt\n"
       ]
      }
     ],
     "prompt_number": 82
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "def sliding_peak_freq(dictionary, data_raw, window):\n",
      "    '''\n",
      "    takes a window size in ms and does non-overlapping count (which is freq, since the windows are all the same size) and average ibi. \n",
      "    returns two dataframes with this information for each 'test' case.\n",
      "    '''\n",
      "    import math\n",
      "    num = math.trunc(data_raw.index[-1]/window) #get the number of windows to do the counts and averages over.\n",
      "    \n",
      "    sliding_count = DataFrame(index= (np.arange(num)*window)) #where we're storing the results for each timeseries\n",
      "    sliding_mean = DataFrame(index= (np.arange(num)*window)) #where we're storing the results for each timeseries\n",
      "    \n",
      "    for key, value in dictionary.iteritems():\n",
      "        \n",
      "        temp_count = Series(index= (np.arange(num)*window)) #temp storage\n",
      "        temp_mean = Series(index= (np.arange(num)*window)) #temp storage\n",
      "        \n",
      "        for i in (np.arange(num)*window):\n",
      "            temp_count[i] = value['Interval'][i:(i+window)].count() #get the count in the window\n",
      "            temp_mean[i] = value['Interval'][i:(i+window)].mean() #get the mean in the window\n",
      "        \n",
      "        temp_mean = temp_mean.fillna(0) #temp mean returns NaN for windows with no events. make it zero for graphing\n",
      "        \n",
      "        sliding_count[key] = temp_count #store series in results table\n",
      "        sliding_mean[key] = temp_mean #store series in results table\n",
      "    \n",
      "    sliding_count = sliding_count.sort_index(axis = 1)\n",
      "    sliding_mean = sliding_mean.sort_index(axis = 1) #my attempt at reordering so the columns are in increaing order\n",
      "    return sliding_mean, sliding_count\n",
      "\n",
      "\n",
      "def sliding_burst_freq(dictionary, data_raw, window):\n",
      "    '''\n",
      "    takes a window size in ms and does non-overlapping count (which is freq, since the windows are all the same size) and average ibi. \n",
      "    returns two dataframes with this information for each 'test' case.\n",
      "    '''\n",
      "    \n",
      "    import math\n",
      "    num = math.trunc(data_raw.index[-1]/window) #get the number of windows to do the counts and averages over.\n",
      "    \n",
      "    sliding_count = DataFrame(index= (np.arange(num)*window)) #where we're storing the results for each timeseries\n",
      "    sliding_mean_dur = DataFrame(index= (np.arange(num)*window)) #where we're storing the results for each timeseries\n",
      "    sliding_mean_dur = DataFrame(index= (np.arange(num)*window))\n",
      "    \n",
      "    for key, value in dictionary.iteritems():\n",
      "        \n",
      "        temp_count = Series(index= (np.arange(num)*window)) #temp storage\n",
      "        temp_mean_dur = Series(index= (np.arange(num)*window)) #temp storage\n",
      "        \n",
      "        for i in (np.arange(num)*window):\n",
      "            temp_count[i] = value['Duration'][i:(i+window)].count() #get the count in the window\n",
      "            temp_mean_dur[i] = value['Duration'][i:(i+window)].mean() #get the mean in the window\n",
      "        \n",
      "        temp_mean = temp_mean_dur.fillna(0) #temp mean returns NaN for windows with no events. make it zero for graphing\n",
      "        \n",
      "        sliding_count[key] = temp_count #store series in results table\n",
      "        sliding_mean_dur[key] = temp_mean #store series in results table\n",
      "    \n",
      "    sliding_count = sliding_count.sort_index(axis = 1)\n",
      "    sliding_mean = sliding_mean_dur.sort_index(axis = 1) #my attempt at reordering so the columns are in increaing order\n",
      "    return sliding_mean, sliding_count"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 83
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "window = 1000 #set window size, no overlap"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 84
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "sliding_p_mean, sliding_p_count = sliding_peak_freq(peaks, data_raw,  window = window)\n",
      "#output_dict['sliding_p_mean_'] = sliding_p_mean\n",
      "#output_dict['sliding_p_count_'] = sliding_p_count\n",
      "peak_c_m = pd.concat({'peak count':sliding_p_count, 'peak mean':sliding_p_mean}, axis=1).to_sparse()\n",
      "#output_dict['sliding_peaks_']=peak_c_m"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 85
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "sliding_b_mean, sliding_b_count = sliding_burst_freq(bursts, data_raw,  window = window)\n",
      "#output_dict['sliding_b_count_'] = sliding_b_count\n",
      "#output_dict['sliding_b_mean_'] = sliding_b_mean\n",
      "burst_c_m = pd.concat({'burst count':sliding_b_count, 'burst mean':sliding_b_mean}, axis=1).to_sparse()\n",
      "#output_dict['sliding_bursts_']=burst_c_m"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 86
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "save_file = os.path.join(output_directory,'sliding_burst_cm-'+output_suffix)\n",
      "print save_file\n",
      "pd.DataFrame().from_dict(burst_c_m.to_dict()).to_csv(save_file)\n",
      "\n",
      "save_file = os.path.join(output_directory,'sliding_peak_cm-'+output_suffix)\n",
      "print save_file\n",
      "pd.DataFrame().from_dict(peak_c_m.to_dict()).to_csv(save_file)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "C:\\Users\\mfinemorris\\repos\\WilsonLab\\NMAnalysis\\sliding_burst_cm-TBModel-sec300-IP-gL2_5.txt\n",
        "C:\\Users\\mfinemorris\\repos\\WilsonLab\\NMAnalysis\\sliding_peak_cm-TBModel-sec300-IP-gL2_5.txt\n"
       ]
      }
     ],
     "prompt_number": 87
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "#save sliding data"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "#quick sharex plot of count and raw data for a given test varible \n",
      "foo = '0.95'\n",
      "fig, ax = plt.subplots(2, sharex= True)\n",
      "ax[0].plot(data_raw.index, data_raw[foo])\n",
      "ax[1].plot(sliding_p_count.index, sliding_p_count[foo], marker = '.')\n",
      "fig.subplots_adjust(hspace = 0.1)\n",
      "plt.show()"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 88
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "rd_index = data_raw.index\n",
      "p_index = sliding_p_count.index\n",
      "for num, key in enumerate(data_raw[1:]):\n",
      "    peak_data = sliding_p_count[key]\n",
      "    raw_data = data_raw[key]\n",
      "    \n",
      "    fig = plt.figure(num)\n",
      "    fig.subplots_adjust(hspace=0.1)\n",
      "\n",
      "    ax1 = plt.subplot(211)\n",
      "    ax1.plot(rd_index, raw_data)\n",
      "    plt.ylabel('Membrane Potential (mV)')\n",
      "    plt.title(\"sliding peak count, \" + variable + \" = \"+ key)\n",
      "\n",
      "    ax2 = plt.subplot(212, sharex=ax1)\n",
      "    ax2.plot(p_index, peak_data, marker = '.')\n",
      "    plt.xlabel(\"Time (ms)\")\n",
      "    plt.ylabel(\"# Peaks\")\n",
      "    \n",
      "    plot_file = os.path.join(output_directory,\"sliding_peaks-\"+key.replace(\".\",\"_\")+\"-\"+plot_suffix)\n",
      "    print plot_file\n",
      "    fig.savefig(plot_file)\n",
      "plt.show()"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "C:\\Users\\mfinemorris\\repos\\WilsonLab\\NMAnalysis\\sliding_peaks-0_9-TBModel-sec300-IP-gL2_5.png\n",
        "C:\\Users\\mfinemorris\\repos\\WilsonLab\\NMAnalysis\\sliding_peaks-0_95-TBModel-sec300-IP-gL2_5.png"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "C:\\Users\\mfinemorris\\repos\\WilsonLab\\NMAnalysis\\sliding_peaks-1_0-TBModel-sec300-IP-gL2_5.png"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "C:\\Users\\mfinemorris\\repos\\WilsonLab\\NMAnalysis\\sliding_peaks-1_2-TBModel-sec300-IP-gL2_5.png"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n"
       ]
      }
     ],
     "prompt_number": 127
    },
    {
     "cell_type": "heading",
     "level": 2,
     "metadata": {},
     "source": [
      "Optional Blocks"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "#all time series overlay\n",
      "plt.plot(data_raw, label= data_raw.columns)\n",
      "plt.xlim(xmin = 30000, xmax = 45000)\n",
      "plt.show()"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 30
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "#quick plot all events with specail start and end colors.\n",
      "meas = '0.95' #which setting to graph\n",
      "\n",
      "plt.plot(data_raw.index, data_raw[meas], color = 'k')\n",
      "plt.plot(peaks[meas].index, peaks[meas]['Amplitude'], marker ='^', color = 'g', linestyle = 'None')\n",
      "for index, row in bursts[meas]['Start'].iteritems():\n",
      "    plt.plot(row, peaks[meas]['Amplitude'].loc[row], marker ='^', color = 'm', linestyle = 'None')\n",
      "for index, row in bursts[meas]['End'].iteritems():\n",
      "    plt.plot(row, peaks[meas]['Amplitude'].loc[row], marker ='^', color = 'y', linestyle = 'None')\n",
      "#plt.xlim(xmin = 30000, xmax = 45000)\n",
      "plt.title('%s - %s' %(exp, meas))\n",
      "plt.xlabel('Time (ms)')\n",
      "plt.ylabel('Voltage')\n",
      "plt.show()"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 31
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "#quick plot of events\n",
      "label = meas\n",
      "plt.plot(data_raw.index, data_raw[label])\n",
      "plt.plot(peak_sets_temp_x[label], peak_sets_temp_y[label], marker = \"^\", color=\"y\", linestyle= \"None\")\n",
      "plt.title(label)\n",
      "plt.show()"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 33
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 41
    },
    {
     "cell_type": "heading",
     "level": 1,
     "metadata": {},
     "source": [
      "Save out settings and analysis"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "import NMResources as nmr\n",
      "import operator\n",
      "from pprint import pprint\n",
      "import json\n",
      "output_file = os.path.join(output_directory,\"misc-\"+output_suffix+\".csv\")"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 128
    },
    {
     "cell_type": "heading",
     "level": 2,
     "metadata": {},
     "source": [
      "Save Data"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "#make all dataframes into csv strings\n",
      "#separate them from other elements of dictionary\n",
      "formatted_output = {}\n",
      "for i,ii in output_dict.iteritems():\n",
      "    try:\n",
      "        formatted_output[i]=ii.to_dict()\n",
      "    except:\n",
      "        formatted_output[i]=ii\n",
      "        \n",
      "with open(output_file,'w') as f:\n",
      "    json.dump(formatted_output,f)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 129
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "pat_ind = output_dict['peak_amp_temp'].index\n",
      "output_dict['peak_amp_temp']"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "html": [
        "<div style=\"max-height:1000px;max-width:1500px;overflow:auto;\">\n",
        "<table border=\"1\" class=\"dataframe\">\n",
        "  <thead>\n",
        "    <tr style=\"text-align: right;\">\n",
        "      <th></th>\n",
        "      <th>0.9</th>\n",
        "      <th>0.95</th>\n",
        "      <th>1.0</th>\n",
        "      <th>1.2</th>\n",
        "    </tr>\n",
        "  </thead>\n",
        "  <tbody>\n",
        "    <tr>\n",
        "      <th>count</th>\n",
        "      <td>  0</td>\n",
        "      <td> 887.000000</td>\n",
        "      <td> 2148.000000</td>\n",
        "      <td> 3119.000000</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>mean</th>\n",
        "      <td>NaN</td>\n",
        "      <td>   5.209998</td>\n",
        "      <td>    5.450821</td>\n",
        "      <td>    4.641696</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>std</th>\n",
        "      <td>NaN</td>\n",
        "      <td>   1.709528</td>\n",
        "      <td>    1.107147</td>\n",
        "      <td>    6.659212</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>min</th>\n",
        "      <td>NaN</td>\n",
        "      <td> -44.963484</td>\n",
        "      <td>  -45.411611</td>\n",
        "      <td>  -45.888449</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>25%</th>\n",
        "      <td>NaN</td>\n",
        "      <td>   5.015600</td>\n",
        "      <td>    5.360962</td>\n",
        "      <td>    5.484921</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>50%</th>\n",
        "      <td>NaN</td>\n",
        "      <td>   5.246601</td>\n",
        "      <td>    5.472068</td>\n",
        "      <td>    5.540429</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>75%</th>\n",
        "      <td>NaN</td>\n",
        "      <td>   5.508012</td>\n",
        "      <td>    5.575864</td>\n",
        "      <td>    5.589770</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>max</th>\n",
        "      <td>NaN</td>\n",
        "      <td>   5.946941</td>\n",
        "      <td>    5.896579</td>\n",
        "      <td>    5.802625</td>\n",
        "    </tr>\n",
        "  </tbody>\n",
        "</table>\n",
        "</div>"
       ],
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 130,
       "text": [
        "       0.9        0.95          1.0          1.2\n",
        "count    0  887.000000  2148.000000  3119.000000\n",
        "mean   NaN    5.209998     5.450821     4.641696\n",
        "std    NaN    1.709528     1.107147     6.659212\n",
        "min    NaN  -44.963484   -45.411611   -45.888449\n",
        "25%    NaN    5.015600     5.360962     5.484921\n",
        "50%    NaN    5.246601     5.472068     5.540429\n",
        "75%    NaN    5.508012     5.575864     5.589770\n",
        "max    NaN    5.946941     5.896579     5.802625"
       ]
      }
     ],
     "prompt_number": 130
    },
    {
     "cell_type": "heading",
     "level": 2,
     "metadata": {},
     "source": [
      "Extract Data"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "#Extract Data\n",
      "with open(output_file,'r') as f:\n",
      "    misc_data = json.load(f)\n",
      "print misc_data.keys()\n",
      "\n",
      "temp = {}\n",
      "\n",
      "for k,v in misc_data.iteritems():\n",
      "    try:\n",
      "        temp[k] = pd.DataFrame.from_dict(v)\n",
      "        print k\n",
      "    except:\n",
      "        temp[k] = v\n",
      "        print k, \": \", v\n",
      "        \n",
      "temp['peak_amp_temp'].reindex_axis(pat_ind)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "[u'burst_stat_data', u'peak_amp_temp', u'ibi_avg_std', u'ibi_thresh', u'File_Path', u'rate', u'exp', u'sg_setting']\n",
        "burst_stat_data\n",
        "peak_amp_temp\n",
        "ibi_avg_std\n",
        "ibi_thresh :  200\n",
        "File_Path :  C:\\Users\\mfinemorris\\Desktop\\Parallel Model Code\\Results\\voltage-TBModel-sec300-IP-gL2_5.txt\n",
        "rate :  0.100000033333\n",
        "exp :  TBModel with sec300, IP, gL2_5\n",
        "sg_setting :  301\n"
       ]
      },
      {
       "html": [
        "<div style=\"max-height:1000px;max-width:1500px;overflow:auto;\">\n",
        "<table border=\"1\" class=\"dataframe\">\n",
        "  <thead>\n",
        "    <tr style=\"text-align: right;\">\n",
        "      <th></th>\n",
        "      <th>0.9</th>\n",
        "      <th>0.95</th>\n",
        "      <th>1.0</th>\n",
        "      <th>1.2</th>\n",
        "    </tr>\n",
        "  </thead>\n",
        "  <tbody>\n",
        "    <tr>\n",
        "      <th>count</th>\n",
        "      <td>  0</td>\n",
        "      <td> 887.000000</td>\n",
        "      <td> 2148.000000</td>\n",
        "      <td> 3119.000000</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>mean</th>\n",
        "      <td>NaN</td>\n",
        "      <td>   5.209998</td>\n",
        "      <td>    5.450821</td>\n",
        "      <td>    4.641696</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>std</th>\n",
        "      <td>NaN</td>\n",
        "      <td>   1.709528</td>\n",
        "      <td>    1.107147</td>\n",
        "      <td>    6.659212</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>min</th>\n",
        "      <td>NaN</td>\n",
        "      <td> -44.963484</td>\n",
        "      <td>  -45.411611</td>\n",
        "      <td>  -45.888449</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>25%</th>\n",
        "      <td>NaN</td>\n",
        "      <td>   5.015600</td>\n",
        "      <td>    5.360962</td>\n",
        "      <td>    5.484921</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>50%</th>\n",
        "      <td>NaN</td>\n",
        "      <td>   5.246601</td>\n",
        "      <td>    5.472068</td>\n",
        "      <td>    5.540429</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>75%</th>\n",
        "      <td>NaN</td>\n",
        "      <td>   5.508012</td>\n",
        "      <td>    5.575864</td>\n",
        "      <td>    5.589770</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>max</th>\n",
        "      <td>NaN</td>\n",
        "      <td>   5.946941</td>\n",
        "      <td>    5.896579</td>\n",
        "      <td>    5.802625</td>\n",
        "    </tr>\n",
        "  </tbody>\n",
        "</table>\n",
        "</div>"
       ],
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 183,
       "text": [
        "       0.9        0.95          1.0          1.2\n",
        "count    0  887.000000  2148.000000  3119.000000\n",
        "mean   NaN    5.209998     5.450821     4.641696\n",
        "std    NaN    1.709528     1.107147     6.659212\n",
        "min    NaN  -44.963484   -45.411611   -45.888449\n",
        "25%    NaN    5.015600     5.360962     5.484921\n",
        "50%    NaN    5.246601     5.472068     5.540429\n",
        "75%    NaN    5.508012     5.575864     5.589770\n",
        "max    NaN    5.946941     5.896579     5.802625"
       ]
      }
     ],
     "prompt_number": 183
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "#any key in output_dict that is suffixed with \"_\" should get its own file\n",
      "#what should the output file names look like?\n",
      "\n",
      "#make dir with \n",
      "small_info = {}\n",
      "for key,val in output_dict.items():\n",
      "    #print\n",
      "    if key.endswith('_'):\n",
      "        path = output_dict['File_Path']\n",
      "        basefile = os.path.basename(path)\n",
      "        file_name_parts = basefile.split(\"-\")\n",
      "        new_file_name = \"-\".join([key[:-1]]+file_name_parts[1:])\n",
      "        print key, basefile, new_file_name\n",
      "        #print type(val)\n",
      "        #now write file\n",
      "    else:\n",
      "        small_info[key] = val\n",
      "print\n",
      "print small_info\n",
      "output_dict.keys()"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "{'burst_stat_data':       duration mean  duration std     ibi mean    ibi std\n",
        "0.9             NaN           NaN          NaN        NaN\n",
        "0.95     356.812619      7.056491  8567.724731   6.024775\n",
        "1.0      317.836380      8.984696  2602.449887   8.342934\n",
        "1.2      382.375127     13.851072  1441.743773  13.674764, 'peak_amp_temp':        0.9        0.95          1.0          1.2\n",
        "count    0  887.000000  2148.000000  3119.000000\n",
        "mean   NaN    5.209998     5.450821     4.641696\n",
        "std    NaN    1.709528     1.107147     6.659212\n",
        "min    NaN  -44.963484   -45.411611   -45.888449\n",
        "25%    NaN    5.015600     5.360962     5.484921\n",
        "50%    NaN    5.246601     5.472068     5.540429\n",
        "75%    NaN    5.508012     5.575864     5.589770\n",
        "max    NaN    5.946941     5.896579     5.802625, 'ibi_thresh': 200, 'File_Path': 'C:\\\\Users\\\\mfinemorris\\\\Desktop\\\\Parallel Model Code\\\\Results\\\\voltage-TBModel-sec300-IP-gL2_5.txt', 'rate': 0.1000000333333444, 'exp': 'TBModel with sec300, IP, gL2_5', 'sg_setting': 301}\n"
       ]
      },
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 124,
       "text": [
        "['burst_stat_data',\n",
        " 'peak_amp_temp',\n",
        " 'sg_setting',\n",
        " 'File_Path',\n",
        " 'rate',\n",
        " 'exp',\n",
        " 'ibi_thresh']"
       ]
      }
     ],
     "prompt_number": 124
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "def all_time_series(data_raw, peaks, bursts, exp, output_directory):\n",
      "    '''\n",
      "    create and save all time series. requires that event detection has been performed. \n",
      "    saves out plots of graphs with the same scale, 30 s - 45 s.\n",
      "    '''\n",
      "    \n",
      "    for label, column in data_raw.iteritems():\n",
      "        \n",
      "        plt.figure()\n",
      "        plt.plot(data_raw.index, data_raw[label], color = 'k')\n",
      "        plt.plot(peaks[label].index, peaks[label]['Amplitude'], marker ='^', color = 'g', linestyle = 'None')\n",
      "        for index, row in bursts[label]['Start'].iteritems():\n",
      "            plt.plot(row, peaks[label]['Amplitude'].loc[row], marker ='^', color = 'm', linestyle = 'None')\n",
      "        for index, row in bursts[label]['End'].iteritems():\n",
      "            plt.plot(row, peaks[label]['Amplitude'].loc[row], marker ='^', color = 'y', linestyle = 'None')\n",
      "        plt.xlim(xmin = 30000, xmax = 45000)\n",
      "        plt.title('%s - %s' %(exp, label))\n",
      "        plt.xlabel('Time (ms)')\n",
      "        plt.ylabel('Voltage')\n",
      "        plt.savefig(r'%s/Time Series - %s.pdf'%(output_directory, label))\n",
      "        plt.close()\n",
      "\n",
      "all_time_series(data_raw, peaks, bursts, exp, output_directory)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 33
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "for i in plt.get_fignums():\n",
      "    plt.figure(i)\n",
      "    plt.show()\n",
      "    plt.savefig('figure%d.png' % i)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 35
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [],
     "language": "python",
     "metadata": {},
     "outputs": []
    }
   ],
   "metadata": {}
  }
 ]
}